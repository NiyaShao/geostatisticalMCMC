import numpy as np
import pandas as pd
import scipy as sp
#from scipy.interpolate import RBFInterpolator


import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.preprocessing import QuantileTransformer
#from sklearn.metrics import pairwise_distances
import gstatsim as gs
import gstools as gstools
#from mpl_toolkits.axes_grid1 import make_axes_locatable
import skgstat as skg
from skgstat import models
#from matplotlib.colors import LightSource

import random
import time
import math
import os

from PIL import Image, ImageFilter


import geomc


# %load_ext autoreload
# %autoreload 2





xmin_set = 2300000
xmax_set = 2600000
ymin_set = -500000
ymax_set = -300000

resolution = 1000


df = pd.read_csv('Data/compiled_Aurora_noQC_iceshelve_included_3.csv')

velx = np.loadtxt('Data/velx_MEaSUREs_linear.txt')
df['vel_x'] = velx.flatten()
vely = np.loadtxt('Data/vely_MEaSUREs_linear.txt')
df['vel_y'] = vely.flatten()

df = df[(df['X']>xmin_set) & (df['X']<=xmax_set) & (df['Y']>ymin_set) & (df['Y']<=ymax_set)].copy()

x_uniq = np.unique(df.X)
y_uniq = np.unique(df.Y)
cols = len(x_uniq)
rows = len(y_uniq)
xx, yy = np.meshgrid(x_uniq, y_uniq)

print(xx.shape, np.min(xx),np.max(xx),np.min(yy),np.max(yy))


floating_mask = df.bedmachine_mask.values.reshape(xx.shape)
floating_mask = (floating_mask == 0) | (floating_mask == 3)
mask_final = geomc.find_mask(df.vel_x.values.reshape(xx.shape),df.vel_y.values.reshape(xx.shape),50,
                             df.bedmachine_mask.values.reshape(xx.shape)==2,floating_mask,5000,
                             xx,yy)


smb, fig = geomc.load_smb('./Data/SMB_RACMO2.3p2_yearly_ANT27_1979_2016.nc',xx,yy,interp_method='spline')


dhdt, fig = geomc.load_dhdt('./Data/ANT_G1920_GroundedIceHeight_v01.nc',xx,yy,interp_method='linear')


surf = df.surface.values.reshape((rows,cols))
velx = np.loadtxt('Data/velx_MEaSUREs_linear_denman.txt')
vely = np.loadtxt('Data/vely_MEaSUREs_linear_denman.txt')


df_bm = pd.read_csv('./Data/AIS_bedmachine_1000m.csv')
df_bm = df_bm[(df_bm['x']>xmin_set) & (df_bm['x']<=xmax_set) & (df_bm['y']>ymin_set) & (df_bm['y']<=ymax_set)].copy()
df_bm = df_bm.reset_index()


mc_res_bm = geomc.calc_mass_conservation(df_bm.bed.values.reshape(rows,cols), surf, velx, vely, dhdt, smb)
geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = True, high_vel_mask = mask_final)


plt.pcolormesh(xx,yy,mask_final)
plt.axis('scaled')


fig = plt.figure(figsize=(48,32))
plt.quiver(xx/1000, yy/1000, velx, vely, scale_units="x",
           scale=30, width=0.0002, color='red')
plt.pcolormesh(xx/1000, yy/1000,  df_bm.source.values.reshape((rows,cols)), cmap='viridis',alpha=0.2)
plt.axis('scaled')
plt.savefig('totten_vel_vector.png')


df_bed = df.copy()
df_bed = df_bed[df_bed["bed"].isnull() == False]
data = df_bed['bed'].values.reshape(-1,1)
coords = df_bed[['X','Y']].values
roughness_region_mask = (df_bed['bedmachine_mask'].values)==2

nst_trans, Nbed_radar, varios, fig = geomc.fit_variogram(data, coords, roughness_region_mask, maxlag=70000, n_lags=70)


# vario1_radar = [azimuth, nugget, major_range, minor_range, sill, vtype]
tp3 = varios[2]
vario1_radar = [0, 0, tp3[0], tp3[0], tp3[1], 'Spherical']


df_bed['Nbed_radar'] = Nbed_radar.flatten()


k = 48
rad = 60000

Pred_grid_xy = gs.Gridding.prediction_grid(xmin_set+resolution, xmax_set, ymin_set+resolution, ymax_set, resolution)
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.flip(np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))) # need to flip y otherwise the coordinate does not match
Pred_grid_xy = np.concatenate((x,y),axis=1)

sim = gs.Interpolation.okrige_sgs(Pred_grid_xy, df_bed, 'X', 'Y', 'Nbed_radar', k, vario1_radar, rad)

# convert the first SGS matrix to a dataframe
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
xy_grid = np.concatenate((x,y,sim.flatten().reshape(-1,1)),axis=1)
psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)

sgs_bed = nst_trans.inverse_transform(np.array(psimdf['Z']).reshape(-1,1)).reshape(rows,cols)
np.savetxt('./55_prep/sgs_bed_denman_noqc_55preprocess.txt',sgs_bed)


sgs_bed = np.loadtxt('./55_prep/sgs_bed_denman_noqc_55preprocess.txt')


#create the initial topography for preprocessing
iceshelf_mask = (df.bedmachine_mask.values.reshape((rows,cols))==3) | (df.bedmachine_mask.values.reshape((rows,cols))==1) | (df.bedmachine_mask.values.reshape((rows,cols))==0)
bed_mean = np.nanmean(df.bed.values.reshape((rows,cols))[mask_final==1])
bed = np.where(iceshelf_mask,df.bed.values.reshape((rows,cols)), bed_mean)
bed = np.where(mask_final==1,bed,sgs_bed)


plt.pcolormesh(xx,yy,bed)
plt.title('the topography preprocess chain initiate with')
plt.axis('scaled')


mc_res_start = geomc.calc_mass_conservation(bed, surf, velx, vely, dhdt, smb)
print('the mass conservation residual preprocess chain start with')
geomc.loss_mc(mc_res_start, 'sumsq', inside_high_vel_region = True, high_vel_mask = mask_final)


mc_res_bm = geomc.calc_mass_conservation(df_bm.bed.values.reshape(xx.shape), surf, velx, vely, dhdt, smb)
print('the mass conservation residual of bedmachine')
geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = True, high_vel_mask = mask_final)


cond_bed = df.bed.values.reshape((rows,cols))
cond_data_mask = ~np.isnan(cond_bed)


radardiff = df_bm.bed.values.reshape((rows,cols)) - df.bed.values.reshape((rows,cols))
radardiff_sr2 = radardiff[mask_final==1]
mc_res_bm_sr2 = mc_res_bm[mask_final==1]


sigma3 = 3
xl3=np.linspace(-100, 100, num=1000)
gaussian_model=1/(sigma3*np.sqrt(2*np.pi))*np.exp(-0.5*np.square(xl3/sigma3))
#laplacian_model=1/(2*sigma4)*np.exp(-1*np.abs(xl3)/sigma4)

mc_res_bm_f = mc_res_bm.flatten()
mc_res_bm_f = mc_res_bm_f[~np.isnan(mc_res_bm_f)]
mc_res_bm_sr2_f = mc_res_bm_sr2.flatten()
mc_res_bm_sr2_f = mc_res_bm_sr2_f[~np.isnan(mc_res_bm_sr2_f)]
bins=np.histogram(np.hstack((mc_res_bm_f,mc_res_bm_sr2_f)), bins=5000)[1] #get the bin edges

#plt.hist(mc_res_bm_f, bins=bins, facecolor='blue', alpha=0.2,density=True,label='entire domain')
plt.hist(mc_res_bm_sr2_f, bins=bins, facecolor='red', alpha=0.3,density=True,label='BM source == 2')
plt.plot(xl3, gaussian_model, color='Green',alpha=0.6)
#plt.plot(xl3, laplacian_model, color='Orange',alpha=0.6)
plt.xlim([-50,50]);
#plt.ylim([0,0.04])
plt.legend()
plt.xlabel('mass conv residual');
plt.ylabel('Frequency');
plt.title('histogram of mass conservation residual (bedmachine)')
plt.grid(True)
plt.savefig('hist1.png')


sigma3 = 80
xl3=np.linspace(-1000, 1000, num=5000)
gaussian_model=1/(sigma3*np.sqrt(2*np.pi))*np.exp(-0.5*np.square(xl3/sigma3))

radardiff_f = radardiff.flatten()
radardiff_f = radardiff_f[~np.isnan(radardiff_f)]
radardiff_sr2_f = radardiff_sr2.flatten()
radardiff_sr2_f = radardiff_sr2_f[~np.isnan(radardiff_sr2_f)]
bins=np.histogram(np.hstack((radardiff_f,radardiff_sr2_f)), bins=1000)[1] #get the bin edges

#plt.hist(radardiff_f, bins=bins, facecolor='blue', alpha=0.2,density=True,label='entire domain')
plt.hist(radardiff_sr2_f, bins=bins, facecolor='red', alpha=0.2,density=True,label='BM source == 2')
plt.plot(xl3, gaussian_model, color='Green',alpha=0.6)
plt.legend()
plt.xlim([-500,500]); 
plt.ylim([0.0,0.01]); 
plt.xlabel('elevation difference');
plt.ylabel('Frequency');
plt.title('histogram of bm - radar')
plt.grid(True)
plt.savefig('hist2.png')


file_index = '55'


# define parameters
n_iter_list =  [5000] * 12
n_iter_list.append(1000)
n_iter_list.append(1000)
sigma_mc_list = [3] * 14
sigma_data_list = [80] * 14
param_list = [[50e3, 5e3, [50,100], [(50,50),(200,200)]]] * 14
file_postfix_list = ['_'+file_index+'_prep_'+str(i) for i in range(1,13)]
file_postfix_list.append('_'+file_index+'_prep_'+'13foravg')
file_postfix_list.append('_'+file_index+'_prep_'+'14foravg')
choice_param_list = [500] * 12
choice_param_list.append(1)
choice_param_list.append(1)

resolution = 1000
logistic_param = [2,0,6,1]
mc_loss_type = 'sumsq'
data_loss = True
data_loss_type = 'sumsq'
maxdist = vario1_radar[2]
covariance_type = 'Gaussian'
isotropic = True
conditional= False
mcloss_in_high_vel = True
dataloss_in_high_vel = True
onlychange_in_highvel = True


# define parameters
n_iter_list =  [1000,1000]
sigma_mc_list = [3] * 2
sigma_data_list = [80] * 2
param_list = [[50e3, 5e3, [50,100], [(50,50),(200,200)]]] * 2
file_postfix_list = []
file_postfix_list.append('_'+file_index+'_prep_'+'15foravg')
file_postfix_list.append('_'+file_index+'_prep_'+'16foravg')
choice_param_list = [1] * 2

resolution = 1000
logistic_param = [2,0,6,1]
mc_loss_type = 'sumsq'
data_loss = True
data_loss_type = 'sumsq'
maxdist = vario1_radar[2]
covariance_type = 'Gaussian'
isotropic = True
conditional= False
mcloss_in_high_vel = True
dataloss_in_high_vel = True
onlychange_in_highvel = True


loaded_bed_temp = np.loadtxt("./bed_cache_55_prep_14foravg.txt")
loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)


bed = loaded_bed_temp[-1,:,:]


mc_res = geomc.calc_mass_conservation(bed, surf, velx, vely, dhdt, smb)
geomc.loss_mc(mc_res, 'sumsq', inside_high_vel_region = True, high_vel_mask = mask_final)


maxdist


#start crf in stages for easier storage
begin_time = time.time()

for i in range(0,len(n_iter_list)):
    print('the i is ', i)
    
    n_iter = n_iter_list[i]
    file_postfix = file_postfix_list[i]
    choice_param = choice_param_list[i]
    
    range_max = [param_list[i][0], param_list[i][0]]
    range_min = [param_list[i][1], param_list[i][1]]
    step_range = param_list[i][2]
    block_size = param_list[i][3]
    nug_max = 0.0
    
    rfgen_param = [range_max, range_min, step_range, nug_max]
    
    sigma_mc = sigma_mc_list[i]
    sigma_data = sigma_data_list[i]

    bed_cache, loss_mc_cache, loss_data_cache, loss_cache, step_cache, resampled_times, blocks_cache = geomc.sample_both_block_logi(
       bed, surf, velx, vely, dhdt, smb,
       cond_bed, ~np.isnan(cond_bed), resolution,
       n_iter, block_size, rfgen_param, mc_loss_type, sigma_mc, 
       logistic_param = logistic_param, mc_region_mask = mask_final,
       sigma_data = sigma_data, maxdist = maxdist, crf_weight = -1,
       data_loss=data_loss, data_loss_type=data_loss_type, CRF = conditional, 
       mcloss_in_high_vel = mcloss_in_high_vel, dataloss_in_high_vel = dataloss_in_high_vel, onlychange_in_highvel = onlychange_in_highvel, 
       isotropic=isotropic, model_name = covariance_type)

    bed = bed_cache[-1]

    if choice_param == 1:
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[:n_iter,:,:].reshape(n_iter, -1))
    else:
        choice = np.round(np.linspace(0, n_iter-choice_param, num=int(n_iter/choice_param))).astype(int)
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[choice,:,:].reshape(len(choice), -1))

    np.savetxt("loss_cache"+file_postfix+".txt",loss_cache[:n_iter])
    np.savetxt("loss_mc_cache"+file_postfix+".txt",loss_mc_cache[:n_iter])
    np.savetxt("loss_data_cache"+file_postfix+".txt",loss_data_cache[:n_iter])
    np.savetxt("step_cache"+file_postfix+".txt",step_cache[:n_iter])
    np.savetxt("resampled_times"+file_postfix+".txt",resampled_times)
    np.savetxt("blocks_cache"+file_postfix+".txt",blocks_cache)
    
end_time = time.time()
used_time = end_time - begin_time
print('used ', used_time, ' seconds')





n_iter_list_1 =  [5000] * 12
param_list_1 = [[50e3, 5e3, [50,200], [(50,50),(200,200)]]] * 12
file_postfix_list_1 = ['_55_prep_'+str(i) for i in range(1,13)]
choice_param_list_1 = [500] * 12


n_iter_list_1 =  [1000] * 4
param_list_1 = [[50e3, 5e3, [50,200], [(50,50),(200,200)]]] * 4
file_postfix_list_1 = ['_55_prep_'+str(i)+'foravg' for i in range(13,17)]
choice_param_list_1 = [1] * 4


mc_loss_1 = np.zeros(np.sum(n_iter_list_1))
data_loss_1 = np.zeros(np.sum(n_iter_list_1))
step_1 = np.zeros(np.sum(n_iter_list_1))
blocks_1 = np.zeros((np.sum(n_iter_list_1),4))
for i in range(len(n_iter_list_1)):
    file_postfix = file_postfix_list_1[i]
    mc_loss_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./loss_mc_cache"+file_postfix+".txt")
    data_loss_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./loss_data_cache"+file_postfix+".txt")
    step_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./step_cache"+file_postfix+".txt")
    blocks_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./blocks_cache"+file_postfix+".txt")


# load file
nsil = np.floor(np.divide(n_iter_list_1, choice_param_list_1)).astype(int)
loaded_bed_1 = np.zeros((np.sum(nsil), rows, cols))
resampled_times_1 = np.zeros((len(n_iter_list_1), rows, cols))
for i in range(len(nsil)):
    file_postfix = file_postfix_list_1[i]
    loaded_bed_temp = np.loadtxt("./bed_cache"+file_postfix+".txt")
    loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)
    loaded_bed_1[int(np.sum(nsil[:i])):int(np.sum(nsil[:i+1])),:,:] = loaded_bed_temp
    resampled_times_1[i,:,:] = np.loadtxt("./resampled_times"+file_postfix+".txt").reshape(rows, cols)
    
mse_loss_1 = np.zeros(np.sum(nsil))
for i in range(loaded_bed_1.shape[0]):
    mc_res_now = geomc.calc_mass_conservation(loaded_bed_1[i], surf, velx, vely, dhdt, smb)
    mse_loss_1[i] = geomc.loss_mc(mc_res_now, 'sumabs', inside_high_vel_region = False)


loss_mc_bm = geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = True, high_vel_mask = mask_final)
loss_mc_bm


loss_data_bm = geomc.loss_data(df_bm.bed.values.reshape(xx.shape), cond_bed, cond_data_mask, 
                              'sumsq', inside_high_vel_region = True, high_vel_mask = mask_final)
loss_data_bm


fig = geomc.plot_loss(np.array([mc_loss_1]), np.array([step_1]), loss_mc_bm, has_dataloss = True, 
                      loss_data_cache = np.array([data_loss_1]), data_loss_bm = loss_data_bm)


fig = geomc.plot_sample(loaded_bed_1, resampled_times_1, xx, yy)


plt.pcolormesh(xx,yy,loaded_bed_1[-1],vmax=2000,vmin=-2500,cmap='gist_earth')
#plt.pcolormesh(xx,yy,cond_bed,vmax=2000,vmin=-2500,cmap='grey')
plt.axis('scaled')


plt.figure(figsize=(16,14))
plt.pcolormesh(xx,yy,loaded_bed_1[-1]-cond_bed,vmax=500,vmin=-500,cmap='RdBu')
plt.colorbar()
plt.axis('scaled')


plt.pcolormesh(xx,yy,cond_bed,vmax=2000,vmin=-2500,cmap='gist_earth')
plt.colorbar()
plt.axis('scaled')


geomc.loss_data(loaded_bed_1[-1], cond_bed, cond_data_mask, 
                'sumsq', inside_high_vel_region = True, high_vel_mask = mask_final)


mc_res = geomc.calc_mass_conservation(loaded_bed_1[-1], surf, velx, vely, dhdt, smb)
geomc.loss_mc(mc_res, 'sumsq', inside_high_vel_region = True, high_vel_mask = mask_final)


geomc.loss_mc(mc_res, 'sumsq', inside_high_vel_region = False), geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = False)


plt.pcolormesh(xx,yy,mc_res,vmax=75,vmin=-75,cmap='RdBu')
plt.axis('scaled')
plt.colorbar()


plt.pcolormesh(xx,yy,mc_res_bm,vmax=75,vmin=-75,cmap='RdBu')
plt.axis('scaled')
plt.colorbar()


sigma3 = 3
#sigma4 = 3.8
xl3=np.linspace(-100, 100, num=1000)
gaussian_model=1/(sigma3*np.sqrt(2*np.pi))*np.exp(-0.5*np.square(xl3/sigma3))
#laplacian_model=1/(2*sigma4)*np.exp(-1*np.abs(xl3)/sigma4)

mc_res_bm_sr2 = mc_res_bm[mask_final==1]
mc_res_bm_sr2_f = mc_res_bm_sr2.flatten()
mc_res_bm_sr2_f = mc_res_bm_sr2_f[~np.isnan(mc_res_bm_sr2_f)]
mc_res_sr2 = mc_res[mask_final==1]
mc_res_sr2_f = mc_res_sr2.flatten()
mc_res_sr2_f = mc_res_sr2_f[~np.isnan(mc_res_sr2_f)]
bins=np.histogram(np.hstack((mc_res_sr2_f,mc_res_bm_sr2_f)), bins=5000)[1] #get the bin edges

plt.hist(mc_res_sr2_f, bins=bins, facecolor='blue', alpha=0.2,density=True,label='end topo')
plt.hist(mc_res_bm_sr2_f, bins=bins, facecolor='red', alpha=0.3,density=True,label='BM')
plt.plot(xl3, gaussian_model, color='Green',alpha=0.6)
#plt.plot(xl3, laplacian_model, color='Orange',alpha=0.6)
plt.xlim([-50,50]);
#plt.ylim([0,0.04])
plt.legend()
plt.xlabel('mass conv residual');
plt.ylabel('Frequency');
plt.title('histogram of mass conservation residual')
plt.grid(True)
plt.show()





avg_beds = np.loadtxt("./55_prep/bed_cache_55_prep_13foravg"+".txt")
avg_beds = avg_beds.reshape(np.round(avg_beds.size/(rows*cols)).astype(int), rows, cols)
avg_bed = np.mean(avg_beds, axis=0)


plt.pcolormesh(xx,yy,avg_bed,vmax=2000,vmin=-2500,cmap='gist_earth')
#plt.pcolormesh(xx,yy,cond_bed,vmax=2000,vmin=-2500,cmap='grey')
plt.axis('scaled')


avg_beds2 = np.loadtxt("./bed_cache_"+"38_1_14foravg"+".txt")
avg_beds2 = avg_beds2.reshape(np.round(avg_beds2.size/(rows*cols)).astype(int), rows, cols)
avg_bed2 = np.mean(avg_beds2, axis=0)


plt.pcolormesh(xx,yy,avg_bed2,vmax=2000,vmin=-2500,cmap='gist_earth')
#plt.pcolormesh(xx,yy,cond_bed,vmax=2000,vmin=-2500,cmap='grey')
plt.axis('scaled')


plt.pcolormesh(xx,yy,avg_bed - avg_bed2,vmax=100,vmin=-100,cmap='RdBu')
plt.axis('scaled')


plt.pcolormesh(xx,yy,avg_beds[0,:,:] - avg_beds[-1,:,:],vmax=100,vmin=-100,cmap='RdBu')
plt.colorbar()
plt.axis('scaled')


plt.pcolormesh(xx,yy,avg_beds2[0,:,:] - avg_beds2[-1,:,:],vmax=100,vmin=-100,cmap='RdBu')
plt.axis('scaled')


n_iter_list_avg =  [1000] * 4
file_postfix_list_avg = ['_55_prep_'+str(i)+'foravg' for i in range(13,17)]
choice_param_list_avg = [1] * 4


# load file
nsil = np.floor(np.divide(n_iter_list_avg, choice_param_list_avg)).astype(int)
loaded_bed_avg = np.zeros((np.sum(nsil), rows, cols))
for i in range(len(nsil)):
    file_postfix = file_postfix_list_avg[i]
    loaded_bed_temp = np.loadtxt("./55_prep/bed_cache"+file_postfix+".txt")
    loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)
    loaded_bed_avg[int(np.sum(nsil[:i])):int(np.sum(nsil[:i+1])),:,:] = loaded_bed_temp


avg_bed = np.mean(loaded_bed_avg, axis=0)


df_out = geomc.exclude_data_rf(df, avg_bed, cond_bed, 1.5, xx, yy, shallow=True)
df_out = df_out.reset_index()


186*1.5


plt.pcolormesh(xx,yy,df_out.bedQCrf.values.reshape(xx.shape))


xcmin = 80
xcmax = 107
ycmin = 130
ycmax = 175


bmradardiff = df_bm.bed.values.reshape(xx.shape) - cond_bed
stdbm = np.nanstd(bmradardiff)
plt.pcolormesh(xx[xcmin:xcmax,ycmin:ycmax],yy[xcmin:xcmax,ycmin:ycmax],bmradardiff[xcmin:xcmax,ycmin:ycmax],vmax=stdbm*1.8,vmin=-stdbm*1.8, cmap='RdBu')
plt.colorbar()
plt.axis('scaled')


plt.pcolormesh(xx[xcmin:xcmax,ycmin:ycmax],yy[xcmin:xcmax,ycmin:ycmax],bmradardiff[xcmin:xcmax,ycmin:ycmax]<-stdbm*2, cmap='RdBu')
plt.colorbar()
plt.axis('scaled')


xpmin = xx[xcmin,ycmin]
xpmax = xx[xcmax,ycmax]
ypmin = yy[xcmin,ycmin]
ypmax = yy[xcmax,ycmax]


exclude_index = df_bm[((df_bm.bed-df_out.bedQCrf)<-stdbm*2)&(df_bm.x>=xpmin)&(df_bm.x<=xpmax)&(df_bm.y>=ypmin)&(df_bm.y<=ypmax)&(df_out.bedQCrf!=np.nan)].index


df_out.loc[exclude_index,'bedQCrf'] = np.nan


np.savetxt('denman_extra_excluded_index_55.txt',exclude_index.values)


# df_out2 = geomc.exclude_data_neariceshelf(df_out,1000,3,dfmaskname='bedmachine_mask',bedindex='bedQCrf')


# plt.pcolormesh(xx,yy,df_out2.bedQCrf.values.reshape(xx.shape))
# plt.scatter(df_out.iloc[exclude_index].X,df_out.iloc[exclude_index].Y,s=0.5,color='red')


# df_out2['mask'] = mask_final.flatten()


# df_out2.to_csv('./compiled_Denman_QC_38_1_shallow.csv', index=False, header=True)  


df_out['mask'] = mask_final.flatten()


df_out.to_csv('./compiled_Denman_QC_55_shallow.csv', index=False, header=True)  


df = df.reset_index()


df_excluded = df[(~df['bed'].isna())&(df_out['bedQCrf'].isna())]


df_excluded


df_excluded.to_csv('./excluded_Denman_QC_55_shallow.csv', index=False, header=True)


df_out[(~df_out.bed.isna())&(df_out['mask']==True)]


plt.pcolormesh(xx/1000,yy/1000,df_out.bedQCrf.values.reshape(xx.shape), cmap='gist_earth')
plt.colorbar(aspect=30, label='bed elevation (m)',orientation='horizontal')
plt.scatter(df_excluded.X/1000,df_excluded.Y/1000,s=0.5,color='red')
plt.xlabel('X [km]')
plt.ylabel('Y [km]')
plt.axis('scaled')
plt.title('excluded data (red) and remained conditioning elevation data')
plt.savefig('excluded_radar_data.png',bbox_inches='tight',dpi=300)





df = pd.read_csv('./compiled_Denman_QC_38_1_shallow.csv')
df=df.rename(columns={"bed": "bed_notpreprocessed"})
df=df.rename(columns={"bedQCrf": "bed"})

x_uniq = np.unique(df.X)
y_uniq = np.unique(df.Y)

xmin = np.min(x_uniq)
xmax = np.max(x_uniq)
ymin = np.min(y_uniq)
ymax = np.max(y_uniq)

cols = len(x_uniq)
rows = len(y_uniq)

resolution = 1000

xx, yy = np.meshgrid(x_uniq, y_uniq)
xx.shape


smb, fig1 = geomc.load_smb('./Data/SMB_RACMO2.3p2_yearly_ANT27_1979_2016.nc',xx,yy)
dhdt, fig2 = geomc.load_dhdt('./Data/ANT_G1920_GroundedIceHeight_v01.nc',xx,yy)
surf = df.surface.values.reshape((rows,cols))
velx = df.vel_x.values.reshape((rows,cols))
vely = df.vel_y.values.reshape((rows,cols))

data_index = df[df["bed"].isnull() == False].index
mask_index = df[df["mask"]==1].index


df_bed = df.copy()
df_bed = df_bed[df_bed["bed"].isnull() == False]
data = df_bed['bed'].values.reshape(-1,1)
coords = df_bed[['X','Y']].values
roughness_region_mask = (df_bed['bedmachine_mask'].values)==2

nst_trans, Nbed_radar, varios, fig = geomc.fit_variogram(data, coords, roughness_region_mask, maxlag=70000, n_lags=70)


# save variogram parameters as a list
# vario1_radar = [azimuth, nugget, major_range, minor_range, sill, vtype]
vario1_radar = [0, 0, 45687.9402279064, 45687.9402279064, 1.4012725206478585, 'Spherical']


df_bed['Nbed_radar'] = Nbed_radar.flatten()


k = 48
rad = 50000

Pred_grid_xy = gs.Gridding.prediction_grid(xmin, xmax, ymin, ymax, resolution)
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.flip(np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))) # need to flip y otherwise the coordinate does not match
Pred_grid_xy = np.concatenate((x,y),axis=1)

sim = gs.Interpolation.okrige_sgs(Pred_grid_xy, df_bed, 'X', 'Y', 'Nbed_radar', k, vario1_radar, rad)

# convert the first SGS matrix to a dataframe
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
xy_grid = np.concatenate((x,y,sim.flatten().reshape(-1,1)),axis=1)
psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)

sgs_bed = nst_trans.inverse_transform(np.array(psimdf['Z']).reshape(-1,1)).reshape(rows,cols)
np.savetxt('sgs_bed_38_3.txt',sgs_bed)



sgs_bed = np.loadtxt('sgs_bed_38_3.txt')


plt.pcolormesh(xx,yy,sgs_bed)


cond_bed = df.bed.values.reshape((rows,cols))
cond_data_mask = ~np.isnan(cond_bed)


weight, dist, dist_rescale, dist_logi = geomc.get_crf_weight(xx,yy,logistic_param,cond_data_mask,max_dist=vario1_radar[2])


field = geomc.generate_RF(x_uniq,y_uniq,step_range,nug_max,range_min,range_max,model_name='Exponential',isotropic=True)


ds = [field,
      dist_rescale,
      weight,
      field * weight ]
titles = ['a random field', 'rescaled distance', 'condition weights', 'a conditioned random field']
cmaps = ['RdBu_r','viridis','viridis','RdBu_r']

fig, axs = plt.subplots(2, 2, figsize=(8.5,7), sharey=True, sharex=True,
                       gridspec_kw={'wspace':-0.01})

for ax, d, t, c in zip(axs.ravel(), ds, titles, cmaps):
    im = ax.pcolormesh(xx/1000, yy/1000, d, cmap=c)
    ax.set_title(t)
    ax.axis('scaled')
    plt.colorbar(im, ax=ax, pad=0.03, aspect=40)
plt.show()


df_bm = pd.read_csv('./Data/Aurora_bedmachine_data.csv')
df_bm = df_bm[(df_bm['x']>=xmin) & (df_bm['x']<=xmax) & (df_bm['y']>=ymin) & (df_bm['y']<=ymax)].copy()
df_bm = df_bm.reset_index()
mc_res_bm = geomc.calc_mass_conservation(df_bm.bed.values.reshape(rows,cols), surf, velx, vely, dhdt, smb)


loaded_bed_temp = np.loadtxt("./bed_cache"+'_38_3_40'+".txt")
loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)


#bed = sgs_bed
bed = loaded_bed_temp[-1]


80000
every 4000 iteration sampled once, sample 20 times
80000 iters
4000 choice
1. sampled interval
2. resulting ensemble
3. use them as start topography for the sgs





40*5000


first plot autocorrelation of cells in crf
run a 5000 iter chain with choice = 1
record value of certain grid outside of the general bed
get the autocorrelation of randomly selected points on the map


index_xy, actual_xy = geomc.find_example_loc(30, cond_data_mask, mc_region_mask, xx, yy)


    color = ['#377eb8', '#ff7f00', '#4daf4a',
              '#f781bf', '#a65628', '#984ea3',
              '#999999', '#e41a1c', '#dede00','#57bee8',
            '#377eb8', '#ff7f00', '#4daf4a',
              '#f781bf', '#a65628', '#984ea3',
              '#999999', '#e41a1c', '#dede00','#57bee8',
            '#377eb8', '#ff7f00', '#4daf4a',
              '#f781bf', '#a65628', '#984ea3',
              '#999999', '#e41a1c', '#dede00','#57bee8']


#plt.pcolormesh(xx,yy,trend,vmax=2000,vmin=-2500,cmap='gist_earth')
plt.pcolormesh(xx,yy,cond_data_mask,cmap='grey',alpha=0.2)
plt.pcolormesh(xx,yy,mc_region_mask,cmap='grey',alpha=0.2)
plt.scatter(actual_xy[:,0],actual_xy[:,1],s=5,c=color)
plt.axis('scaled')


#define parameters
n_iter_list =  [5000] * 4
sigma_mc_list = [3] * 4
sigma_data_list = [-1] * 4
param_list = [[50e3, 10e3, [50,200], [(30,30),(70,70)]]] * 4
file_postfix_list = ['_38_3_'+str(i)+'forsample' for i in range(41,45)]
choice_param_list = [4000] * 4

resolution = 1000
logistic_param = [2,0,6,1]
mc_loss_type = 'sumsq'
data_loss = False
data_loss_type = 'default'
maxdist = vario1_radar[2]
covariance_type = 'Exponential'
isotropic = True
conditional= True
mcloss_in_high_vel = True
dataloss_in_high_vel = True
onlychange_in_highvel = True


#define parameters
n_iter_list =  [20000] * 4
sigma_mc_list = [3] * 4
sigma_data_list = [-1] * 4
param_list = [[50e3, 10e3, [50,200], [(30,30),(70,70)]]] * 4
file_postfix_list = ['_38_3_'+str(i)+'forsample' for i in range(41,45)]
choice_param_list = [4000] * 4

resolution = 1000
logistic_param = [2,0,6,1]
mc_loss_type = 'sumsq'
data_loss = False
data_loss_type = 'default'
maxdist = vario1_radar[2]
covariance_type = 'Exponential'
isotropic = True
conditional= True
mcloss_in_high_vel = True
dataloss_in_high_vel = True
onlychange_in_highvel = True


#start crf in stages for easier storage
for i in range(0,len(n_iter_list)):
    n_iter = n_iter_list[i]
    file_postfix = file_postfix_list[i]
    choice_param = choice_param_list[i]
    
    range_max = [param_list[i][0], param_list[i][0]]
    range_min = [param_list[i][1], param_list[i][1]]
    step_range = param_list[i][2]
    block_size = param_list[i][3]
    nug_max = 0.0
    
    rfgen_param = [range_max, range_min, step_range, nug_max]
    
    sigma_mc = sigma_mc_list[i]
    sigma_data = sigma_data_list[i]

    bed_cache, loss_mc_cache, loss_cache, step_cache, resampled_times, blocks_cache = geomc.sample_both_block_logi(
       bed, surf, velx, vely, dhdt, smb,
       cond_bed, ~np.isnan(cond_bed), resolution,
       n_iter, block_size, rfgen_param, mc_loss_type, sigma_mc, 
       logistic_param = logistic_param, mc_region_mask = mc_region_mask,
       sigma_data = sigma_data, maxdist = maxdist, crf_weight = weight,
       data_loss=data_loss, data_loss_type=data_loss_type, CRF = conditional, 
       mcloss_in_high_vel = mcloss_in_high_vel, dataloss_in_high_vel = dataloss_in_high_vel, onlychange_in_highvel = onlychange_in_highvel, 
       isotropic=isotropic, model_name = covariance_type)
    
    example_values = bed_cache[:,index_xy[:,0].astype('int'),index_xy[:,1].astype('int')]

    bed = bed_cache[-1]

    if choice_param == 1: # save all data
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[:n_iter,:,:].reshape(n_iter, -1))
    else: # save a topo per choice_param topo
        choice = np.round(np.linspace(0, n_iter-1, num=int(n_iter/choice_param))).astype(int)
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[choice,:,:].reshape(len(choice), -1))

    np.savetxt("example_values"+file_postfix+".txt",example_values)
    np.savetxt("loss_cache"+file_postfix+".txt",loss_cache)
    np.savetxt("loss_mc_cache"+file_postfix+".txt",loss_mc_cache)
    #np.savetxt("loss_data_cache"+file_postfix+".txt",loss_data_cache[:n_iter])
    #np.savetxt("loss_data_in_cache"+file_postfix+".txt",loss_data_in_cache[:n_iter])
    #np.savetxt("loss_data_out_cache"+file_postfix+".txt",loss_data_out_cache[:n_iter])
    np.savetxt("step_cache"+file_postfix+".txt",step_cache)
    np.savetxt("resampled_times"+file_postfix+".txt",resampled_times)
    np.savetxt("blocks_cache"+file_postfix+".txt",blocks_cache)


example_values = np.zeros((10000,30))
example_values[:5000,:]=np.loadtxt('./example_values_38_3_41forautocorr.txt')
example_values[5000:,:]=np.loadtxt('./example_values_38_3_42forautocorr.txt')
example_values.shape
fig = geomc.plot_autocorr(example_values.T)


n_iter_list_1 =  [5000] * 40
param_list_1 = [[50e3, 5e3, [50,200], [(50,50),(200,200)]]] * 40
file_postfix_list_1 = ['_38_3_'+str(i) for i in range(1,41)]
choice_param_list_1 = [500] * 40


mc_loss_1 = np.zeros(np.sum(n_iter_list_1))
#data_loss_1 = np.zeros(np.sum(n_iter_list_1))
step_1 = np.zeros(np.sum(n_iter_list_1))
blocks_1 = np.zeros((np.sum(n_iter_list_1),4))
for i in range(len(n_iter_list_1)):
    file_postfix = file_postfix_list_1[i]
    mc_loss_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./loss_mc_cache"+file_postfix+".txt")
    #data_loss_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./loss_data_cache"+file_postfix+".txt")
    step_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./step_cache"+file_postfix+".txt")
    blocks_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./blocks_cache"+file_postfix+".txt")


# load file
nsil = np.floor(np.divide(n_iter_list_1, choice_param_list_1)).astype(int)
loaded_bed_1 = np.zeros((np.sum(nsil), rows, cols))
resampled_times_1 = np.zeros((len(n_iter_list_1), rows, cols))
for i in range(len(nsil)):
    file_postfix = file_postfix_list_1[i]
    loaded_bed_temp = np.loadtxt("./bed_cache"+file_postfix+".txt")
    loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)
    loaded_bed_1[int(np.sum(nsil[:i])):int(np.sum(nsil[:i+1])),:,:] = loaded_bed_temp
    resampled_times_1[i,:,:] = np.loadtxt("./resampled_times"+file_postfix+".txt").reshape(rows, cols)
    
mse_loss_1 = np.zeros(np.sum(nsil))
for i in range(loaded_bed_1.shape[0]):
    mc_res_now = geomc.calc_mass_conservation(loaded_bed_1[i], surf, velx, vely, dhdt, smb)
    mse_loss_1[i] = geomc.loss_mc(mc_res_now, 'sumabs', inside_high_vel_region = False)


mc_loss_2 = np.zeros(np.sum(n_iter_list_2))
data_loss_2 = np.zeros(np.sum(n_iter_list_2))
step_2 = np.zeros(np.sum(n_iter_list_2))
blocks_2 = np.zeros((np.sum(n_iter_list_2),4))
for i in range(len(n_iter_list_2)):
    file_postfix = file_postfix_list_2[i]
    mc_loss_2[int(np.sum(n_iter_list_2[:i])):int(np.sum(n_iter_list_2[:i+1]))] = np.loadtxt("./loss_mc_cache"+file_postfix+".txt")
    data_loss_2[int(np.sum(n_iter_list[:i])):int(np.sum(n_iter_list[:i+1]))] = np.loadtxt("./loss_data_cache"+file_postfix+".txt")
    step_2[int(np.sum(n_iter_list_2[:i])):int(np.sum(n_iter_list_2[:i+1]))] = np.loadtxt("./step_cache"+file_postfix+".txt")
    blocks_2[int(np.sum(n_iter_list_2[:i])):int(np.sum(n_iter_list_2[:i+1]))] = np.loadtxt("./blocks_cache"+file_postfix+".txt")


# load file
nsil = np.floor(np.divide(n_iter_list_2, choice_param_list_2)).astype(int)
loaded_bed_2 = np.zeros((np.sum(nsil), rows, cols))
resampled_times_2 = np.zeros((len(n_iter_list_2), rows, cols))
for i in range(len(nsil)):
    file_postfix = file_postfix_list_2[i]
    loaded_bed_temp = np.loadtxt("./bed_cache"+file_postfix+".txt")
    loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)
    loaded_bed_2[int(np.sum(nsil[:i])):int(np.sum(nsil[:i+1])),:,:] = loaded_bed_temp
    resampled_times_2[i,:,:] = np.loadtxt("./resampled_times"+file_postfix+".txt").reshape(rows, cols)
    
mse_loss_2 = np.zeros(np.sum(nsil))
for i in range(loaded_bed_2.shape[0]):
    mc_res_now = geomc.calc_mass_conservation(loaded_bed_2[i], surf, velx, vely, dhdt, smb)
    mse_loss_2[i] = geomc.loss_mc(mc_res_now, 'sumabs', inside_high_vel_region = False)


loss_mc_bm = geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = True, high_vel_mask = mc_region_mask)


fig = geomc.plot_loss(np.array([mc_loss_1]), np.array([step_1]), loss_mc_bm, has_dataloss = False)


fig = geomc.plot_sample(loaded_bed_1[28*10:], resampled_times_1[28:], xx, yy)


plt.pcolormesh(xx,yy,loaded_bed_1[-1],vmax=2000,vmin=-2500,cmap='gist_earth')
plt.axis('scaled')


loss_mc_bm = geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = True, high_vel_mask = mask_final)
loss_mc_bm


mc_res = geomc.calc_mass_conservation(loaded_bed_1[-1], surf, velx, vely, dhdt, smb)
loss_mc_chain_in = geomc.loss_mc(mc_res, 'sumsq', inside_high_vel_region = True, high_vel_mask = mc_region_mask)
loss_mc_chain_all = geomc.loss_mc(mc_res, 'sumsq', inside_high_vel_region = False)
loss_mc_bm_in = geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = True, high_vel_mask = mc_region_mask)
loss_mc_bm_all = geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = False)

print('for the mc region sumsq loss, the end topo is', loss_mc_chain_in,'the bm is', loss_mc_bm_in)
print('for the global sumsq loss, the end topo is', loss_mc_chain_all,'the bm is', loss_mc_bm_all)


plt.pcolormesh(xx,yy,mc_res,vmax=35,vmin=-35,cmap='RdBu')
plt.colorbar()
plt.pcolormesh(xx,yy,mc_region_mask,cmap='grey',alpha=0.2)
plt.axis('scaled')


plt.pcolormesh(xx,yy,mc_res_bm,vmax=35,vmin=-35,cmap='RdBu')
plt.colorbar()
plt.pcolormesh(xx,yy,df_bm['source'].values.reshape(xx.shape)==2,cmap='grey',alpha=0.2)
plt.axis('scaled')


sigma3 = 3
sigma4 = 3.8
xl3=np.linspace(-100, 100, num=1000)
gaussian_model=1/(sigma3*np.sqrt(2*np.pi))*np.exp(-0.5*np.square(xl3/sigma3))
laplacian_model=1/(2*sigma4)*np.exp(-1*np.abs(xl3)/sigma4)

mc_res_bm_sr2 = mc_res_bm[mask_final==1]
mc_res_bm_sr2_f = mc_res_bm_sr2.flatten()
mc_res_bm_sr2_f = mc_res_bm_sr2_f[~np.isnan(mc_res_bm_sr2_f)]
mc_res_sr2 = mc_res[mask_final==1]
mc_res_sr2_f = mc_res_sr2.flatten()
mc_res_sr2_f = mc_res_sr2_f[~np.isnan(mc_res_sr2_f)]
bins=np.histogram(np.hstack((mc_res_sr2_f,mc_res_bm_sr2_f)), bins=5000)[1] #get the bin edges

plt.hist(mc_res_sr2_f, bins=bins, facecolor='blue', alpha=0.2,density=True,label='end topo')
plt.hist(mc_res_bm_sr2_f, bins=bins, facecolor='red', alpha=0.3,density=True,label='BM')
plt.plot(xl3, gaussian_model, color='Green',alpha=0.6)
#plt.plot(xl3, laplacian_model, color='Orange',alpha=0.6)
plt.xlim([-50,50]);
#plt.ylim([0,0.04])
plt.legend()
plt.xlabel('mass conv residual');
plt.ylabel('Frequency');
plt.title('histogram of mass conservation residual')
plt.grid(True)
plt.show()


plt.figure(figsize=(16,12))
plt.pcolormesh(xx,yy,loaded_bed_1[-1]-loaded_bed_1[-10],cmap='RdBu',vmax=100,vmin=-100)
plt.colorbar()
plt.axis('scaled')


plt.figure(figsize=(16,12))
plt.pcolormesh(xx,yy,loaded_bed_1[-1]-df_bm.bed.values.reshape(xx.shape),cmap='RdBu',vmax=2000,vmin=-2000)
plt.colorbar()
plt.pcolormesh(xx,yy,mc_region_mask,cmap='grey',alpha=0.2)
plt.axis('scaled')


bed_filtered1 = sp.ndimage.gaussian_filter(loaded_bed_1[-10], sigma=2)
bed_filtered2 = sp.ndimage.gaussian_filter(loaded_bed_1[-30], sigma=2)


plt.pcolormesh(xx,yy,bed_filtered1,vmax=2000,vmin=-2500,cmap='gist_earth')
plt.axis('scaled')


plt.pcolormesh(xx,yy,bed_filtered2,vmax=2000,vmin=-2500,cmap='gist_earth')
plt.axis('scaled')


plt.figure(figsize=(16,12))
plt.pcolormesh(xx,yy,bed_filtered1-bed_filtered2,cmap='RdBu',vmax=50,vmin=-50)
plt.colorbar()
plt.pcolormesh(xx,yy,mc_region_mask,cmap='grey',alpha=0.2)
plt.axis('scaled')


plt.figure(figsize=(16,12))
plt.pcolormesh(xx,yy,bed_filtered1-bed_filtered2,cmap='RdBu',vmax=50,vmin=-50)
plt.colorbar()
plt.pcolormesh(xx,yy,mc_region_mask,cmap='grey',alpha=0.2)
plt.axis('scaled')


plt.figure(figsize=(16,12))
plt.pcolormesh(xx,yy,bed_filtered1-bed_filtered2,cmap='RdBu',vmax=100,vmin=-100)
plt.colorbar()
plt.pcolormesh(xx,yy,mc_region_mask,cmap='grey',alpha=0.2)
plt.axis('scaled')


plt.figure(figsize=(16,12))
plt.pcolormesh(xx,yy,bed_filtered1-bed_filtered2,cmap='RdBu',vmax=100,vmin=-100)
plt.colorbar()
plt.pcolormesh(xx,yy,mc_region_mask,cmap='grey',alpha=0.2)
plt.axis('scaled')





avg_beds = np.loadtxt("./bed_cache_"+"38_3_41foravg"+".txt")
avg_beds = avg_beds.reshape(np.round(avg_beds.size/(rows*cols)).astype(int), rows, cols)
avg_bed = np.mean(avg_beds, axis=0)
bed_avged_filtered = sp.ndimage.gaussian_filter(avg_bed, sigma=2)


plt.pcolormesh(xx,yy,bed_avged_filtered,vmax=2000,vmin=-2500,cmap='gist_earth')
plt.axis('scaled')


np.savetxt('trend_38_3.txt',bed_avged_filtered)








df = pd.read_csv('./compiled_Denman_QC_38_1_shallow.csv')
df=df.rename(columns={"bed": "bed_notpreprocessed"})
df=df.rename(columns={"bedQCrf": "bed"})

x_uniq = np.unique(df.X)
y_uniq = np.unique(df.Y)

xmin = np.min(x_uniq)
xmax = np.max(x_uniq)
ymin = np.min(y_uniq)
ymax = np.max(y_uniq)

cols = len(x_uniq)
rows = len(y_uniq)

resolution = 1000

xx, yy = np.meshgrid(x_uniq, y_uniq)
xx.shape


## calculate resiudal
trend = np.loadtxt('trend_38_3.txt')
df['residual']=df['bed'].values-trend.flatten()
print(np.max(df.residual),np.mean(df.residual),np.std(df.residual),np.min(df.residual))


smb, fig1 = geomc.load_smb('./Data/SMB_RACMO2.3p2_yearly_ANT27_1979_2016.nc',xx,yy)
dhdt, fig2 = geomc.load_dhdt('./Data/ANT_G1920_GroundedIceHeight_v01.nc',xx,yy)
surf = df.surface.values.reshape((rows,cols))
velx = df.vel_x.values.reshape((rows,cols))
vely = df.vel_y.values.reshape((rows,cols))

data_index = df[df["bed"].isnull() == False].index
mask_index = df[df["mask"]==1].index


df_bed = df.copy()
df_bed = df_bed[df_bed["residual"].isnull() == False]
data = df_bed['residual'].values.reshape(-1,1)
coords = df_bed[['X','Y']].values
roughness_region_mask = (df_bed['bedmachine_mask'].values)==2

nst_trans, Nbed_detrend, fig = geomc.fit_variogram(data, coords, roughness_region_mask, maxlag=10000, n_lags=500, samples=0.9)


# save variogram parameters as a list
# vario1_radar = [azimuth, nugget, major_range, minor_range, sill, vtype]
vario1_detrend = [0, 0, 4547.163671124821, 4547.163671124821, 1.585033212132834, 'Spherical']


df_bed['Nbed_detrend'] = Nbed_detrend.flatten()


k = 48
rad = 50000

Pred_grid_xy = gs.Gridding.prediction_grid(xmin, xmax, ymin, ymax, resolution)
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.flip(np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))) # need to flip y otherwise the coordinate does not match
Pred_grid_xy = np.concatenate((x,y),axis=1)

sim = gs.Interpolation.okrige_sgs(Pred_grid_xy, df_bed, 'X', 'Y', 'Nbed_detrend', k, vario1_detrend, rad)

# convert the first SGS matrix to a dataframe
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
xy_grid = np.concatenate((x,y,sim.flatten().reshape(-1,1)),axis=1)
psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)

sgs_bed = nst_trans.inverse_transform(np.array(psimdf['Z']).reshape(-1,1)).reshape(rows,cols)
np.savetxt('sgs_bed_38_4.txt',sgs_bed)


sgs_bed = np.loadtxt('sgs_bed_38_4.txt')


plt.figure(figsize=(8,16))

plt.subplot(2,1,1)
plt.pcolormesh(xx,yy,sgs_bed)
plt.axis('scaled')
plt.colorbar()

plt.subplot(2,1,2)
plt.pcolormesh(xx,yy,sgs_bed + trend)
plt.axis('scaled')
plt.colorbar()


cond_bed = df.bed.values.reshape((rows,cols))
cond_data_mask = ~np.isnan(cond_bed)


df_bm = pd.read_csv('./Data/Aurora_bedmachine_data.csv')
df_bm = df_bm[(df_bm['x']>=xmin) & (df_bm['x']<=xmax) & (df_bm['y']>=ymin) & (df_bm['y']<=ymax)].copy()
df_bm = df_bm.reset_index()
mc_res_bm = geomc.calc_mass_conservation(df_bm.bed.values.reshape(rows,cols), surf, velx, vely, dhdt, smb)


mc_region_mask = df['mask'].values.reshape(xx.shape)


loaded_bed_temp = np.loadtxt("bed_cache"+'_38_3_40'+".txt")
loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)


res_bed = loaded_bed_temp[-1] - trend
norm_res_bed = nst_trans.transform(res_bed.reshape(-1,1)).reshape(rows,cols)
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
xy_grid = np.concatenate((x,y,norm_res_bed.flatten().reshape(-1,1)),axis=1)
psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)


testbed = nst_trans.inverse_transform(np.array(psimdf['Z']).reshape(-1,1)).reshape(rows,cols) + trend
plt.pcolormesh(xx,yy,testbed)
plt.colorbar()


#start with end bed of crf chain

n_iter_list = [10000]*30
block_size_list = [((2,2),(8,8))]*30
file_postfix_list = ['_38_4_'+str(i) for i in range(1,31)]
choice_param_list = [500] * 30
sigma_mc_list = [3]*30

resolution = 1000
mc_loss_type = 'sumsq'
sigma_mc = 3
mcloss_in_high_vel = True
searching_radius = 20000
num_nearest_neighbors = 48
rand_dropout = False
dropoutrate = -1


#start crf in stages for easier storage
for i in range(0,len(n_iter_list)):
    n_iter = n_iter_list[i]
    file_postfix = file_postfix_list[i]
    choice_param = choice_param_list[i]

    sigma_mc = sigma_mc_list[i]
    block_size = block_size_list[i]
    
    bed_cache, loss_mc_cache, loss_cache, step_cache, resampled_times, blocks_cache = geomc.sgs_chain(psimdf,'X', 'Y', 'Z', 
          nst_trans, trend, resolution, vario1_detrend,
          cond_data_mask, mc_region_mask,
          surf, velx, vely, dhdt, smb,
          n_iter, block_size, 
          mc_loss_type, sigma_mc, mcloss_in_high_vel,
          searching_radius, num_nearest_neighbors,
          rand_dropout, dropoutrate)
    
    res_bed = bed_cache[-1] - trend
    norm_res_bed = nst_trans.transform(res_bed.reshape(-1,1)).reshape(rows,cols)
    x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
    y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
    xy_grid = np.concatenate((x,y,norm_res_bed.flatten().reshape(-1,1)),axis=1)
    psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)

    if choice_param == 1: # save all data
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[:n_iter,:,:].reshape(n_iter, -1))
    else: # save a topo per choice_param topo
        choice = np.round(np.linspace(0, n_iter-1, num=int(n_iter/choice_param))).astype(int)
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[choice,:,:].reshape(len(choice), -1))

    np.savetxt("loss_cache"+file_postfix+".txt",loss_cache[:n_iter])
    np.savetxt("loss_mc_cache"+file_postfix+".txt",loss_mc_cache[:n_iter])
    #np.savetxt("loss_data_cache"+file_postfix+".txt",loss_data_cache[:n_iter])
    #np.savetxt("loss_data_in_cache"+file_postfix+".txt",loss_data_in_cache[:n_iter])
    #np.savetxt("loss_data_out_cache"+file_postfix+".txt",loss_data_out_cache[:n_iter])
    np.savetxt("step_cache"+file_postfix+".txt",step_cache[:n_iter])
    np.savetxt("resampled_times"+file_postfix+".txt",resampled_times)
    np.savetxt("blocks_cache"+file_postfix+".txt",blocks_cache)


n_iter_list_1 =  [10000] * 12
file_postfix_list_1 = ['_38_4_'+str(i) for i in range(1,13)]
choice_param_list_1 = [500] * 12


mc_loss_1 = np.zeros(np.sum(n_iter_list_1))
#data_loss_1 = np.zeros(np.sum(n_iter_list_1))
step_1 = np.zeros(np.sum(n_iter_list_1))
blocks_1 = np.zeros((np.sum(n_iter_list_1),4))
for i in range(len(n_iter_list_1)):
    file_postfix = file_postfix_list_1[i]
    mc_loss_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./loss_mc_cache"+file_postfix+".txt")
    #data_loss_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./loss_data_cache"+file_postfix+".txt")
    step_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./step_cache"+file_postfix+".txt")
    blocks_1[int(np.sum(n_iter_list_1[:i])):int(np.sum(n_iter_list_1[:i+1]))] = np.loadtxt("./blocks_cache"+file_postfix+".txt")


# load file
nsil = np.floor(np.divide(n_iter_list_1, choice_param_list_1)).astype(int)
loaded_bed_1 = np.zeros((np.sum(nsil), rows, cols))
resampled_times_1 = np.zeros((len(n_iter_list_1), rows, cols))
for i in range(len(nsil)):
    file_postfix = file_postfix_list_1[i]
    loaded_bed_temp = np.loadtxt("./bed_cache"+file_postfix+".txt")
    loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)
    loaded_bed_1[int(np.sum(nsil[:i])):int(np.sum(nsil[:i+1])),:,:] = loaded_bed_temp
    resampled_times_1[i,:,:] = np.loadtxt("./resampled_times"+file_postfix+".txt").reshape(rows, cols)
    
mse_loss_1 = np.zeros(np.sum(nsil))
for i in range(loaded_bed_1.shape[0]):
    mc_res_now = geomc.calc_mass_conservation(loaded_bed_1[i], surf, velx, vely, dhdt, smb)
    mse_loss_1[i] = geomc.loss_mc(mc_res_now, 'sumabs', inside_high_vel_region = False)


plt.pcolormesh(xx,yy,loaded_bed_1[-1],vmax=2000,vmin=-2500,cmap='gist_earth')
plt.axis('scaled')


plt.pcolormesh(xx,yy,loaded_bed_1[-1]-cond_bed)
plt.colorbar()
plt.axis('scaled')


loss_mc_bm = geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = True, high_vel_mask = mc_region_mask)
loss_mc_bm


fig = geomc.plot_loss(np.array([mc_loss_1]), np.array([step_1]), loss_mc_bm, has_dataloss = False)


fig = geomc.plot_sample(loaded_bed_1, np.array([resampled_times[:]]), xx, yy)


mc_res = geomc.calc_mass_conservation(loaded_bed_1[-1], surf, velx, vely, dhdt, smb)
loss_mc_chain_in = geomc.loss_mc(mc_res, 'sumsq', inside_high_vel_region = True, high_vel_mask = mc_region_mask)
loss_mc_chain_all = geomc.loss_mc(mc_res, 'sumsq', inside_high_vel_region = False)
loss_mc_bm_in = geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = True, high_vel_mask = mc_region_mask)
loss_mc_bm_all = geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = False)

print('for the mc region sumsq loss, the end topo is', loss_mc_chain_in,'the bm is', loss_mc_bm_in)
print('for the global sumsq loss, the end topo is', loss_mc_chain_all,'the bm is', loss_mc_bm_all)


plt.pcolormesh(xx,yy,mc_res,vmax=35,vmin=-35,cmap='RdBu')
plt.colorbar()
plt.pcolormesh(xx,yy,mc_region_mask,cmap='grey',alpha=0.2)
plt.axis('scaled')


plt.pcolormesh(xx,yy,mc_res_bm,vmax=35,vmin=-35,cmap='RdBu')
plt.colorbar()
plt.pcolormesh(xx,yy,df_bm['source'].values.reshape(xx.shape)==2,cmap='grey',alpha=0.2)
plt.axis('scaled')


sigma3 = 3
sigma4 = 3.8
xl3=np.linspace(-100, 100, num=1000)
gaussian_model=1/(sigma3*np.sqrt(2*np.pi))*np.exp(-0.5*np.square(xl3/sigma3))
laplacian_model=1/(2*sigma4)*np.exp(-1*np.abs(xl3)/sigma4)

mc_res_bm_sr2 = mc_res_bm[mc_region_mask==1]
mc_res_bm_sr2_f = mc_res_bm_sr2.flatten()
mc_res_bm_sr2_f = mc_res_bm_sr2_f[~np.isnan(mc_res_bm_sr2_f)]
mc_res_sr2 = mc_res[mc_region_mask==1]
mc_res_sr2_f = mc_res_sr2.flatten()
mc_res_sr2_f = mc_res_sr2_f[~np.isnan(mc_res_sr2_f)]
bins=np.histogram(np.hstack((mc_res_sr2_f,mc_res_bm_sr2_f)), bins=5000)[1] #get the bin edges

plt.hist(mc_res_sr2_f, bins=bins, facecolor='blue', alpha=0.2,density=True,label='end topo')
plt.hist(mc_res_bm_sr2_f, bins=bins, facecolor='red', alpha=0.3,density=True,label='BM')
plt.plot(xl3, gaussian_model, color='Green',alpha=0.6)
#plt.plot(xl3, laplacian_model, color='Orange',alpha=0.6)
plt.xlim([-50,50]);
#plt.ylim([0,0.04])
plt.legend()
plt.xlabel('mass conv residual');
plt.ylabel('Frequency');
plt.title('histogram of mass conservation residual')
plt.grid(True)
plt.show()


plt.figure(figsize=(16,12))
plt.pcolormesh(xx,yy,loaded_bed_1[-1]-loaded_bed_1[0],cmap='RdBu',vmax=1,vmin=-1)
plt.colorbar()
plt.axis('scaled')


plt.figure(figsize=(16,12))
plt.pcolormesh(xx,yy,loaded_bed_1[-1]-df_bm.bed.values.reshape(xx.shape),cmap='RdBu',vmax=2000,vmin=-2000)
plt.colorbar()
plt.pcolormesh(xx,yy,mc_region_mask,cmap='grey',alpha=0.2)
plt.axis('scaled')


























df = pd.read_csv('./Data/compiled_Totten_QC_iceshelve_included_modeling.csv')

df=df.rename(columns={"bed": "bed_notpreprocessed"})
df=df.rename(columns={"bedQCrf": "bed"})

x_uniq = np.unique(df.X)
y_uniq = np.unique(df.Y)

xmin = np.min(x_uniq)
xmax = np.max(x_uniq)
ymin = np.min(y_uniq)
ymax = np.max(y_uniq)

cols = len(x_uniq)
rows = len(y_uniq)

resolution = 500

xx, yy = np.meshgrid(x_uniq, y_uniq)
xx.shape


smb, fig = geomc.load_smb('./Data/SMB_RACMO2.3p2_yearly_ANT27_1979_2016.nc',xx,yy)


dhdt, fig = geomc.load_dhdt('./Data/ANT_G1920_GroundedIceHeight_v01.nc',xx,yy)


#initialize vars
surf = df.surface.values.reshape((rows,cols))
velx = df.vel_x.values.reshape((rows,cols))
vely = df.vel_y.values.reshape((rows,cols))

data_index = df[df["bed"].isnull() == False].index
mask_index = df[df["mask"]==1].index


df_bm = pd.read_csv('./Data/aurora_bedmachine_modeling.csv')
df_bm = df_bm[(df_bm['x']>=xmin) & (df_bm['x']<=xmax) & (df_bm['y']>=ymin) & (df_bm['y']<=ymax)].copy()
df_bm = df_bm.reset_index()
df_bm


mc_region_mask = df['mask'].values.reshape(xx.shape)
mc_res_bm = geomc.calc_mass_conservation(df_bm.bed.values.reshape(rows,cols), surf, velx, vely, dhdt, smb)


range_max = [30e3, 30e3]
range_min = [10e3, 10e3]
step_range = [50,51]
nug_max = 0.0
logistic_param = [2,0,6,1]
max_dist = 20000


# dist = np.loadtxt('./output/dist.txt')

# iceshelf_mask = (df_bm['mask'].values.reshape((rows,cols))==3) | (df_bm['mask'].values.reshape((rows,cols))==1) | (df_bm['mask'].values.reshape((rows,cols))==0) 

# df_bed = df.copy()
# radarbed = df_bed['bed'].values.reshape(xx.shape)
# bmbed = df_bm['bed'].values.reshape(xx.shape)
# cond_bed = np.where(mc_region_mask,radarbed,bmbed)
# cond_bed = np.where(iceshelf_mask,radarbed,cond_bed)   

# df_bedxy = df.copy()
# df_bedxy['bed'] = cond_bed.flatten()
# df_bedxy = df_bedxy[df_bedxy['bed'].isnull()]
# sim_index = df_bedxy.index

# df['dist'] = 0.0
# df.loc[sim_index, 'dist'] = dist
# dist_matrix = df.dist.values.reshape(xx.shape)

#np.savetxt('./output/dist_matrix.txt',dist_matrix)


dist_matrix = np.loadtxt('./output/dist_matrix.txt')


dist_rescale = geomc.rescale(dist_matrix, max_dist)
dist_logi = geomc.logistic(dist_rescale, logistic_param[0], logistic_param[1], logistic_param[2]) - logistic_param[3]
weight = dist_logi - np.min(dist_logi)
field = geomc.generate_RF(x_uniq,y_uniq,step_range,nug_max,range_min,range_max,model_name='Exponential',isotropic=True)


ds = [field,
      dist_rescale,
      weight,
      field * weight ]
titles = ['a random field', 'rescaled distance', 'condition weights', 'a conditioned random field']
cmaps = ['RdBu_r','viridis','viridis','RdBu_r']

fig, axs = plt.subplots(2, 2, figsize=(8.5,7), sharey=True, sharex=True,
                       gridspec_kw={'wspace':-0.01})

for ax, d, t, c in zip(axs.ravel(), ds, titles, cmaps):
    im = ax.pcolormesh(xx/1000, yy/1000, d, cmap=c)
    ax.set_title(t)
    ax.axis('scaled')
    plt.colorbar(im, ax=ax, pad=0.03, aspect=40)
plt.show()


plt.pcolormesh(xx,yy,df['bed'].values.reshape(xx.shape))
plt.colorbar()


df_bed = df.copy()
df_bed['bed'] = cond_bed.flatten()
df_bed = df_bed[(~df_bed['bed'].isnull())]

data = cond_bed[~np.isnan(cond_bed)].reshape(-1,1)
nst_trans = QuantileTransformer(n_quantiles=500, output_distribution="normal",random_state=0).fit(data)
df_bed.loc[:,'Nbed_radar'] = nst_trans.transform(data)


# df_bed = df.copy()
# df_bed = df_bed[df_bed['bed'].isnull()==False]

# data = df_bed['bed'].values.reshape(-1,1)
# nst_trans = QuantileTransformer(n_quantiles=500, output_distribution="normal",random_state=0).fit(data)
# df_bed.loc[:,'Nbed_radar'] = nst_trans.transform(data)


sim = np.loadtxt('./output/aurora_sim_40_1.txt')

xy_grid = np.array([df.X.values.flatten(),df.Y.values.flatten(),df.bed.values.flatten()])
psimdf = pd.DataFrame(data = xy_grid.T,columns=['X','Y','Z'],index=df.index)
psimdf.loc[df_bed.index,'Z'] = df_bed.Nbed_radar.values
psimdf.loc[sim_index,'Z'] = sim

bed = nst_trans.inverse_transform(np.array(psimdf['Z']).reshape(-1,1)).reshape(rows,cols)


np.savetxt('./output/aurora_sim_40_1_aftertransform.txt',bed)


bed = np.loadtxt('./output/aurora_sim_40_1_aftertransform.txt')


plt.pcolormesh(xx,yy,bed)
plt.colorbar()


#find the start topography
loaded_bed_cache = np.loadtxt("bed_cache_40_3_1.txt")
bed_cache = loaded_bed_cache.reshape(np.round(loaded_bed_cache.size/(rows*cols)).astype(int), rows, cols)
bed = bed_cache[-1]

mc_res = calc_mass_conservation(bed, surf, velx, vely, dhdt, smb)
print('initial mc res is ', geomc.loss_mc(mc_res, 'sumsq', inside_high_vel_region = False))





#define parameters
n_iter_list =  [1000] * 1
sigma_mc_list = [3.2] * 1
sigma_data_list = [50] * 1
param_list = [[30e3, 10e3, [50,200], [(60,60),(140,140)]]] * 1
file_postfix_list = ['_40_3_'+str(i) for i in range(81,93)]
choice_param_list = [10] * 1

resolution = 500
covariance_type = 'Exponential'
logistic_param = [2,0,6,1]
isotropic = True
mc_loss_type = 'sumsq'
maxdist = 80000


#start crf in stages for easier storage
for i in range(0,len(n_iter_list)):
    n_iter = n_iter_list[i]
    file_postfix = file_postfix_list[i]
    choice_param = choice_param_list[i]
    
    range_max = [param_list[i][0], param_list[i][0]]
    range_min = [param_list[i][1], param_list[i][1]]
    step_range = param_list[i][2]
    block_size = param_list[i][3]
    nug_max = 0.0
    
    rfgen_param = [range_max, range_min, step_range, nug_max]
    
    sigma_mc = sigma_mc_list[i]
    sigma_data = sigma_data_list[i]

    bed_cache, loss_mc_cache, loss_cache, step_cache, resampled_times, blocks_cache = geomc.sample_both_block_logi(
       bed, surf, velx, vely, dhdt, smb,
       cond_bed, ~np.isnan(cond_bed), resolution,
       n_iter, block_size, rfgen_param, mc_loss_type, sigma_mc, 
       logistic_param = logistic_param, mc_region_mask = df['mask'].values.reshape(xx.shape),
       sigma_data = sigma_data, maxdist = maxdist, crf_weight = weight,
       data_loss=True, data_loss_type='sumsq', CRF = True, mcloss_in_high_vel = True, onlychange_in_highvel = True, 
       isotropic=True, model_name='Gaussian')

    bed = bed_cache[-1]

    if choice_param == 1: # save all data
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[:n_iter,:,:].reshape(n_iter, -1))
    else: # save a topo per choice_param topo
        choice = np.round(np.linspace(0, n_iter-1, num=int(n_iter/choice_param))).astype(int)
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[choice,:,:].reshape(len(choice), -1))

    np.savetxt("loss_cache"+file_postfix+".txt",loss_cache[:n_iter])
    np.savetxt("loss_mc_cache"+file_postfix+".txt",loss_mc_cache[:n_iter])
    #np.savetxt("loss_data_cache"+file_postfix+".txt",loss_data_cache[:n_iter])
    np.savetxt("loss_data_in_cache"+file_postfix+".txt",loss_data_in_cache[:n_iter])
    np.savetxt("loss_data_out_cache"+file_postfix+".txt",loss_data_out_cache[:n_iter])
    np.savetxt("step_cache"+file_postfix+".txt",step_cache[:n_iter])
    np.savetxt("resampled_times"+file_postfix+".txt",resampled_times)
    np.savetxt("blocks_cache"+file_postfix+".txt",blocks_cache)





loss_mc_bm = geomc.loss_mc(mc_res_bm, 'sumsq', inside_high_vel_region = False, high_vel_mask = df['mask'].values.reshape(xx.shape))


fig = geomc.plot_loss(np.array([loss_mc_cache]), np.array([step_cache]))


fig = geomc.plot_sample(bed_cache, np.array([resampled_times]), xx, yy)


plt.pcolormesh(xx,yy,bed_cache[0],vmax=500,vmin=-2500,cmap='gist_earth')
plt.axis('scaled')


plt.figure(figsize=(16,12))
plt.pcolormesh(xx,yy,bed_cache[-1]-bed_cache[1],cmap='RdBu')
plt.pcolormesh(xx,yy,-1*df['mask'].values.reshape(xx.shape),cmap='grey',alpha=0.3)
plt.colorbar()
plt.axis('scaled')





os.getcwd()


df = pd.read_csv('../beforeJuly26/compiled_Denman_QC_iceshelve_included_34_1_shallow.csv')
cols = len(np.unique(df['X']))
rows = len(np.unique(df['Y']))


# parameters for plotting and global information
res = 500

cols = len(np.unique(df['X']))
rows = len(np.unique(df['Y']))

x_uniq = np.unique(df.X)
y_uniq = np.unique(df.Y)

xx, yy = np.meshgrid(x_uniq, y_uniq)
xx.shape


ds = [df.bed, np.sqrt(df.vel_x**2+df.vel_y**2), df['mask'], df.surface]
titles = ['ice-penetrating radar data', 'vel magnitude', 'resampling area', 'surface elevation']

fig, axs = plt.subplots(2, 2, figsize=(17,14), sharey=True, sharex=True,
                       gridspec_kw={'wspace':-0.01})

for ax, d, t in zip(axs.ravel(), ds, titles):
    im = ax.pcolormesh(xx/1000, yy/1000, d.values.reshape(xx.shape))
    ax.set_title(t)
    ax.axis('scaled')
    plt.colorbar(im, ax=ax, pad=0.03, aspect=40)
plt.show()


cond_msk = ~np.isnan(df.bed.values.reshape(xx.shape))
cond_mask_2 = df['mask'].values.reshape(xx.shape)==0
cond_msk = cond_mask_2 | cond_msk


def min_dist(hard_mat, xx, yy, xy_list):
    dist = np.zeros(xy_list.shape[0])
    xx_hard = np.where(np.isnan(hard_mat), np.nan, xx)
    yy_hard = np.where(np.isnan(hard_mat), np.nan, yy)
    
    for i in range(xy_list.shape[0]):
        #for j in range(xx.shape[1]):
        dist[i] = np.nanmin(np.sqrt(np.square(xy_list[i,1]-yy_hard)+np.square(xy_list[i,0]-xx_hard)))

        if i%100000 == 0:
            print('get', i, 'values done')
    
    return dist


dfxy = df.copy()
dfxy = dfxy[(dfxy.bed.isnull())&(dfxy['mask'].values == 1)]


xy_list = np.array([dfxy.X.values.flatten(),dfxy.Y.values.flatten()]).T


now = time.time()
dist = min_dist(np.where(cond_msk==0, np.nan, 1), xx, yy, xy_list)
print('used ', time.time()-now, ' seconds')


now = time.time()
dist = min_dist(np.where(cond_msk==0, np.nan, 1), xx, yy, xy_list)
print('used ', time.time()-now, ' seconds')


now = time.time()
dist = min_dist(np.where(cond_msk==0, np.nan, 1), xx, yy, xy_list)
print('used ', time.time()-now, ' seconds')


xy_list.shape


df['dist'] = 0.0


df.loc[dfxy.index, 'dist'] = dist


plt.pcolormesh(xx,yy,df.dist.values.reshape(xx.shape))
plt.colorbar()


plt.pcolormesh(xx,yy,df.dist.values.reshape(xx.shape))
plt.colorbar()



