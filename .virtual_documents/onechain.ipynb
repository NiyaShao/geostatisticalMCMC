import numpy as np
import pandas as pd
import scipy as sp
#from scipy.interpolate import RBFInterpolator


import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.preprocessing import QuantileTransformer
#from sklearn.metrics import pairwise_distances
import gstatsim as gs
import gstools as gstools
#from mpl_toolkits.axes_grid1 import make_axes_locatable
import skgstat as skg
from skgstat import models
#from matplotlib.colors import LightSource

import random
import time
import math
import os

from PIL import Image, ImageFilter

import geomc


%load_ext autoreload
%autoreload 2


file_index = '59'


df = pd.read_csv('./compiled_Denman_QC_55_shallow.csv')
df=df.rename(columns={"bed": "bed_notpreprocessed"})
df=df.rename(columns={"bedQCrf": "bed"})

x_uniq = np.unique(df.X)
y_uniq = np.unique(df.Y)

xmin = np.min(x_uniq)
xmax = np.max(x_uniq)
ymin = np.min(y_uniq)
ymax = np.max(y_uniq)

cols = len(x_uniq)
rows = len(y_uniq)

resolution = 1000

xx, yy = np.meshgrid(x_uniq, y_uniq)
xx.shape


smb, fig1 = geomc.load_smb('./Data/SMB_RACMO2.3p2_yearly_ANT27_1979_2016.nc',xx,yy,interp_method='spline')
dhdt, fig2 = geomc.load_dhdt('./Data/ANT_G1920_GroundedIceHeight_v01.nc',xx,yy,interp_method='linear')
surf = df.surface.values.reshape((rows,cols))
velx = np.loadtxt('Data/velx_MEaSUREs_linear_denman.txt')
vely = np.loadtxt('Data/vely_MEaSUREs_linear_denman.txt')


df_bed = df.copy()
df_bed = df_bed[df_bed["bed"].isnull() == False]
data = df_bed['bed'].values.reshape(-1,1)
coords = df_bed[['X','Y']].values
roughness_region_mask = (df_bed['bedmachine_mask'].values)==2


samples=0.6
subsample=100000
maxlag=90000
n_lags=70


coords = coords[roughness_region_mask==1]
values = data[roughness_region_mask==1].flatten()

test1 = skg.Variogram(coords, values, bin_func='even', n_lags=n_lags, 
                maxlag=maxlag, normalize=False, model='gaussian',samples=samples)
test2 = skg.Variogram(coords, values, bin_func='even', n_lags=n_lags, 
                   maxlag=maxlag, normalize=False, model='exponential',samples=samples)
test3 = skg.Variogram(coords, values, bin_func='even', n_lags=n_lags, 
                   maxlag=maxlag, normalize=False, model='spherical',samples=samples)

tp1 = test1.parameters
tp2 = test2.parameters
tp3 = test3.parameters

print('range, sill, and nugget for gaussian variogram is ', tp1)
print('for exponential variogram is ', tp2)
print('for spherical variogram is ', tp3)

# extract experimental variogram values
xdata1 = test1.bins
ydata1 = test1.experimental
xdata2 = test2.bins
ydata2 = test2.experimental
xdata3 = test3.bins
ydata3 = test3.experimental

# evaluate models
xi = np.linspace(0, xdata2[-1], n_lags) 
y_gauss = [models.gaussian(h, tp1[0], tp1[1], tp1[2]) for h in xi]
y_exp = [models.exponential(h, tp2[0], tp2[1], tp2[2]) for h in xi]
y_sph = [models.spherical(h, tp3[0], tp3[1], tp3[2]) for h in xi]

# plot variogram model
fig = plt.figure(figsize=(6,4))
plt.plot(xi, y_gauss,'b--', label='Gaussian variogram')
plt.plot(xi, y_exp,'b-', label='Exponential variogram')
plt.plot(xi, y_sph,'b*-', label='Spherical variogram')
plt.plot(xdata1, ydata1,'o', markersize=4, color='green', label='Experimental variogram gaussian')
plt.plot(xdata2, ydata2,'o', markersize=4, color='orange', label='Experimental variogram exponential')
plt.plot(xdata3, ydata3,'o', markersize=4, color='pink', label='Experimental variogram spherical')
plt.title('Variogram for synthetic data')
plt.xlabel('Lag [m]'); plt.ylabel('Semivariance')  
plt.legend(loc='lower right')


df_bed = df.copy()
df_bed = df_bed[df_bed["bed"].isnull() == False]
data = df_bed['bed'].values.reshape(-1,1)
coords = df_bed[['X','Y']].values
roughness_region_mask = (df_bed['bedmachine_mask'].values)==2

nst_trans, Nbed_radar, varios, fig = geomc.fit_variogram(data, coords, roughness_region_mask, maxlag=70000, n_lags=70)


# vario1_radar = [azimuth, nugget, major_range, minor_range, sill, vtype]
tp3 = varios[2]
vario1_radar = [0, 0, tp3[0], tp3[0], tp3[1], 'Spherical']


df_bed['Nbed_radar'] = Nbed_radar.flatten()


k = 48
rad = 50000

Pred_grid_xy = gs.Gridding.prediction_grid(xmin, xmax, ymin, ymax, resolution)
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.flip(np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))) # need to flip y otherwise the coordinate does not match
Pred_grid_xy = np.concatenate((x,y),axis=1)

sim = gs.Interpolation.okrige_sgs(Pred_grid_xy, df_bed, 'X', 'Y', 'Nbed_radar', k, vario1_radar, rad)

# convert the first SGS matrix to a dataframe
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
xy_grid = np.concatenate((x,y,sim.flatten().reshape(-1,1)),axis=1)
psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)

sgs_bed = nst_trans.inverse_transform(np.array(psimdf['Z']).reshape(-1,1)).reshape(rows,cols)
np.savetxt('sgs_bed_'+file_index+'_crf.txt',sgs_bed)


sgs_bed = np.loadtxt('sgs_bed_'+file_index+'_crf.txt')


cond_bed = df.bed.values.reshape((rows,cols))
cond_data_mask = ~np.isnan(cond_bed)


mc_region_mask = df['mask'].values.reshape(xx.shape)


df_bm = pd.read_csv('./Data/AIS_bedmachine_1000m.csv')
df_bm = df_bm[(df_bm['x']>=xmin) & (df_bm['x']<=xmax) & (df_bm['y']>=ymin) & (df_bm['y']<=ymax)].copy()
df_bm = df_bm.reset_index()
mc_res_bm = geomc.calc_mass_conservation(df_bm.bed.values.reshape(rows,cols), surf, velx, vely, dhdt, smb)





#define parameters
n_iter_list =  [5000] * 40
n_iter_list.append(4000)
n_iter_list.append(20000)
n_iter_list.append(20000)
sigma_mc_list = [3] * 43
sigma_data_list = [-1] * 43
param_list = [[50e3, 10e3, [50,200], [(30,30),(70,70)]]] * 43
file_postfix_list = ['_'+file_index+'_crf_'+str(i) for i in range(1,41)]
file_postfix_list.append('_'+file_index+'_crf_'+'41foravg')
file_postfix_list.append('_'+file_index+'_crf_'+'42forsample')
file_postfix_list.append('_'+file_index+'_crf_'+'43forsample')
choice_param_list = [1000] * 40
choice_param_list.append(1)
choice_param_list.append(4000)
choice_param_list.append(4000)

resolution = 1000
logistic_param = [2,0,6,1]
mc_loss_type = 'sumsq'
data_loss = False
data_loss_type = 'default'
maxdist = vario1_radar[2]
covariance_type = 'Exponential'
isotropic = True
conditional= True
mcloss_in_high_vel = True
dataloss_in_high_vel = True
onlychange_in_highvel = True


file_index


weight, dist, dist_rescale, dist_logi = geomc.get_crf_weight(xx,yy,logistic_param,cond_data_mask,max_dist=vario1_radar[2])


plt.pcolormesh(xx,yy,(surf-sgs_bed)<=0)
plt.pcolormesh(xx,yy,mc_region_mask,alpha=0.2)


bed = sgs_bed
b = bed[mc_region_mask==1]
s = surf[mc_region_mask==1]
b_r = np.where(b>=s, s-1, b)
bed[mc_region_mask==1] = b_r


plt.pcolormesh(xx,yy,(surf-bed)<=0)
plt.pcolormesh(xx,yy,mc_region_mask,alpha=0.2)


# loaded_bed_temp = np.loadtxt("./bed_cache_"+file_index+'_3_40'+".txt")
# loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)
# bed = loaded_bed_temp[-1,:,:]





# loaded_bed_temp = np.loadtxt("./bed_cache_57_crf_44forsample.txt")
# loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int),rows,cols)
# bed = loaded_bed_temp[-1,:,:]        


mc_res = geomc.calc_mass_conservation(bed, surf, velx, vely, dhdt, smb)
geomc.loss_mc(mc_res, 'sumsq', inside_high_vel_region = True, high_vel_mask = mc_region_mask)


#start crf in stages for easier storage
begin_time = time.time()

for i in range(0,len(n_iter_list)):
    print('the i is ', i)
    
    n_iter = n_iter_list[i]
    file_postfix = file_postfix_list[i]
    choice_param = choice_param_list[i]
    
    range_max = [param_list[i][0], param_list[i][0]]
    range_min = [param_list[i][1], param_list[i][1]]
    step_range = param_list[i][2]
    block_size = param_list[i][3]
    nug_max = 0.0
    
    rfgen_param = [range_max, range_min, step_range, nug_max]
    
    sigma_mc = sigma_mc_list[i]
    sigma_data = sigma_data_list[i]

    bed_cache, loss_mc_cache, loss_cache, step_cache, resampled_times, blocks_cache = geomc.sample_both_block_logi(
       bed, surf, velx, vely, dhdt, smb,
       cond_bed, ~np.isnan(cond_bed), resolution,
       n_iter, block_size, rfgen_param, mc_loss_type, sigma_mc, 
       logistic_param = logistic_param, mc_region_mask = mc_region_mask,
       sigma_data = sigma_data, maxdist = maxdist, crf_weight = weight,
       data_loss=data_loss, data_loss_type=data_loss_type, CRF = conditional, 
       mcloss_in_high_vel = mcloss_in_high_vel, dataloss_in_high_vel = dataloss_in_high_vel, onlychange_in_highvel = onlychange_in_highvel, 
       isotropic=isotropic, model_name = covariance_type)

    bed = bed_cache[-1]

    if choice_param == 1: # save all data
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[:n_iter,:,:].reshape(n_iter, -1))
    else: # save a topo per choice_param topo
        choice = np.round(np.linspace(0, n_iter-choice_param, num=int(n_iter/choice_param))).astype(int)
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[choice,:,:].reshape(len(choice), -1))

    np.savetxt("loss_cache"+file_postfix+".txt",loss_cache[:n_iter])
    np.savetxt("loss_mc_cache"+file_postfix+".txt",loss_mc_cache[:n_iter])
    np.savetxt("step_cache"+file_postfix+".txt",step_cache[:n_iter])
    np.savetxt("resampled_times"+file_postfix+".txt",resampled_times)
    np.savetxt("blocks_cache"+file_postfix+".txt",blocks_cache)

end_time = time.time()
used_time = end_time - begin_time
print('used ', used_time, ' seconds')


file_postfix_list


used_time





# #avg_beds = np.loadtxt("./39_crf/bed_cache_"+file_index+"_crf_41foravg"+".txt")
# #avg_beds = np.loadtxt("bed_cache_50_crf_41foravg.txt")
# avg_beds = np.loadtxt("./58_crf/bed_cache_58_crf_41foravg.txt")
# avg_beds = avg_beds.reshape(np.round(avg_beds.size/(rows*cols)).astype(int), rows, cols)
# avg_bed = np.mean(avg_beds, axis=0)
# bed_avged_filtered = sp.ndimage.gaussian_filter(avg_bed, sigma=5)


#avg_beds = np.loadtxt("./39_crf/bed_cache_"+file_index+"_crf_41foravg"+".txt")
#avg_beds = np.loadtxt("bed_cache_50_crf_41foravg.txt")
avg_beds = np.loadtxt("./bed_cache_59_crf_41foravg.txt")
avg_beds = avg_beds.reshape(np.round(avg_beds.size/(rows*cols)).astype(int), rows, cols)
avg_bed = np.mean(avg_beds, axis=0)
bed_avged_filtered = sp.ndimage.gaussian_filter(avg_bed, sigma=5)


plt.pcolormesh(xx,yy,bed_avged_filtered)
plt.colorbar()


np.savetxt('trend_'+file_index+'_crf.txt',bed_avged_filtered)


df = pd.read_csv('./compiled_Denman_QC_55_shallow.csv')
df=df.rename(columns={"bed": "bed_notpreprocessed"})
df=df.rename(columns={"bedQCrf": "bed"})

x_uniq = np.unique(df.X)
y_uniq = np.unique(df.Y)

xmin = np.min(x_uniq)
xmax = np.max(x_uniq)
ymin = np.min(y_uniq)
ymax = np.max(y_uniq)

cols = len(x_uniq)
rows = len(y_uniq)

resolution = 1000

xx, yy = np.meshgrid(x_uniq, y_uniq)
xx.shape


#folder_name = '38_sgs_ver2'


## calculate resiudal
#trend = np.loadtxt('./trend_'+file_index+'_crf.txt')
trend = np.loadtxt('59_crf/trend_'+file_index+'_crf.txt')
df['residual']=df['bed'].values-trend.flatten()
print(np.max(df.residual),np.mean(df.residual),np.std(df.residual),np.min(df.residual))


smb, fig1 = geomc.load_smb('./Data/SMB_RACMO2.3p2_yearly_ANT27_1979_2016.nc',xx,yy,interp_method='spline')
dhdt, fig2 = geomc.load_dhdt('./Data/ANT_G1920_GroundedIceHeight_v01.nc',xx,yy,interp_method='linear')
surf = df.surface.values.reshape((rows,cols))
velx = np.loadtxt('Data/velx_MEaSUREs_linear_denman.txt')
vely = np.loadtxt('Data/vely_MEaSUREs_linear_denman.txt')


df_bed = df.copy()
df_bed = df_bed[df_bed["residual"].isnull() == False]
data = df_bed['residual'].values.reshape(-1,1)
coords = df_bed[['X','Y']].values
roughness_region_mask = (df_bed['bedmachine_mask'].values)==2

nst_trans, Nbed_detrend, varios, fig = geomc.fit_variogram(data, coords, roughness_region_mask, maxlag=20000, n_lags=500, samples=0.9)


df_bed = df.copy()
df_bed = df_bed[df_bed["residual"].isnull() == False]
data = df_bed['residual'].values.reshape(-1,1)
coords = df_bed[['X','Y']].values
roughness_region_mask = (df_bed['bedmachine_mask'].values)==2

loaded_bed_temp = np.loadtxt("./59_crf/bed_cache_"+file_index+'_crf_42forsample'+".txt")
loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)
data_for_trans = (loaded_bed_temp[0,:,:] - trend).reshape(-1,1)

nst_trans, Nbed_detrend, varios, fig = geomc.fit_variogram(data, coords, roughness_region_mask, 
                                                           maxlag=20000, n_lags=500, samples=0.9,
                                                          data_for_trans=data_for_trans)


df_bed = df.copy()
df_bed = df_bed[df_bed["residual"].isnull() == False]
data = df_bed['residual'].values.reshape(-1,1)
transformed_data = nst_trans.transform(data)
plt.hist(transformed_data.flatten(),bins=100)
plt.show()


df_bed = df.copy()
df_bed = df_bed[df_bed["residual"].isnull() == False]
data = df_bed['residual'].values.reshape(-1,1)
plt.hist(data.flatten(),bins=100)
plt.show()


transformed_data = nst_trans.transform(data_for_trans)
plt.hist(transformed_data.flatten(),bins=100)
plt.show()


plt.hist(data_for_trans.flatten(),bins=100)
plt.show()


tp3 = varios[2]
vario1_detrend = [0, 0, tp3[0], tp3[0], tp3[1], 'Spherical']
df_bed['Nbed_detrend'] = Nbed_detrend.flatten()


vario1_detrend


cond_bed = df.bed.values.reshape((rows,cols))
cond_data_mask = ~np.isnan(cond_bed)


mc_region_mask = df['mask'].values.reshape(xx.shape)


df_bm = pd.read_csv('./Data/AIS_bedmachine_1000m.csv')
df_bm = df_bm[(df_bm['x']>=xmin) & (df_bm['x']<=xmax) & (df_bm['y']>=ymin) & (df_bm['y']<=ymax)].copy()
df_bm = df_bm.reset_index()
mc_res_bm = geomc.calc_mass_conservation(df_bm.bed.values.reshape(rows,cols), surf, velx, vely, dhdt, smb)


file_index


loaded_bed_temp = np.loadtxt("./59_crf/bed_cache_"+file_index+"_crf_42forsample.txt")
loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)


Pred_grid_xy = gs.Gridding.prediction_grid(xmin, xmax, ymin, ymax, resolution)
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.flip(np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))) # need to flip y otherwise the coordinate does not match
Pred_grid_xy = np.concatenate((x,y),axis=1)

res_bed = loaded_bed_temp[-1] - trend
norm_res_bed = nst_trans.transform(res_bed.reshape(-1,1)).reshape(rows,cols)
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
xy_grid = np.concatenate((x,y,norm_res_bed.flatten().reshape(-1,1)),axis=1)
psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)


bed2 = nst_trans.inverse_transform(np.array(psimdf['Z']).reshape(-1,1)).reshape(rows,cols) + trend


plt.pcolormesh(xx,yy,bed2,cmap='gist_earth',vmax=0,vmin=-3500)


plt.pcolormesh(xx,yy,loaded_bed_temp[-1,:,:],cmap='gist_earth',vmax=0,vmin=-3500)


plt.pcolormesh(xx,yy,bed2-loaded_bed_temp[-1,:,:],cmap='RdBu',vmax=50,vmin=-50)
plt.colorbar()


#load all sampled bed
n_iter_list =  [20000] * 2
sigma_mc_list = [3] * 2
file_postfix_list = ['_'+file_index+'_crf_'+str(i)+'forsample' for i in range(42,44)]
choice_param_list = [4000] * 2

nsil = np.floor(np.divide(n_iter_list, choice_param_list)).astype(int)
loaded_bed_sample = np.zeros((np.sum(nsil), rows, cols))
for i in range(len(nsil)):
    file_postfix = file_postfix_list[i]
    loaded_bed_temp = np.loadtxt("./59_crf/bed_cache"+file_postfix+".txt")
    loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)
    loaded_bed_sample[int(np.sum(nsil[:i])):int(np.sum(nsil[:i+1])),:,:] = loaded_bed_temp


num_sgs_chains = loaded_bed_sample.shape[0]
num_sgs_chains


#start with end bed of crf chain
n_iter_list = [10000]*20
block_size_list = [((2,2),(8,8))]*20
choice_param_list = [500] * 20
sigma_mc_list = [3]*20

resolution = 1000
mc_loss_type = 'sumsq'
sigma_mc = 3
mcloss_in_high_vel = True
searching_radius = 50000
num_nearest_neighbors = 48
rand_dropout = False
dropoutrate = -1


plt.figure(figsize=(8,5.5))
plt.pcolormesh(xx/1000, yy/1000, (surf - loaded_bed_sample[6,:,:])<=0)
plt.pcolormesh(xx/1000, yy/1000, mc_region_mask, alpha=0.3)
plt.colorbar(pad=0.02, aspect=40, label='bed thickness (m)')
plt.xlabel('X [km]')
plt.ylabel('Y [km]')
plt.axis('scaled')
plt.show()


plt.figure(figsize=(8,5.5))
plt.pcolormesh(xx/1000, yy/1000, loaded_bed_sample[9,:,:], cmap='gist_earth', vmax=2000,vmin=-2500)
plt.colorbar(pad=0.02, aspect=40, label='bed thickness (m)')
plt.xlabel('X [km]')
plt.ylabel('Y [km]')
plt.axis('scaled')
plt.show()


# bed = loaded_bed_sample[0]
# res_bed = bed - trend
# norm_res_bed = nst_trans.transform(res_bed.reshape(-1,1)).reshape(rows,cols)
# x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
# y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
# xy_grid = np.concatenate((x,y,norm_res_bed.flatten().reshape(-1,1)),axis=1)
# psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)


# bed_next = nst_trans.inverse_transform(np.array(psimdf.Z).reshape(-1,1)).reshape(rows,cols) + trend


# plt.pcolormesh(xx,yy,bed)
# plt.colorbar()
# plt.axis('scaled')


# plt.pcolormesh(xx,yy,bed_next)
# plt.colorbar()
# plt.axis('scaled')


# plt.pcolormesh(xx,yy,bed_next-bed,vmax=500,vmin=-500,cmap='RdBu')
# plt.colorbar()
# plt.pcolormesh(xx,yy,mc_region_mask,cmap='grey',alpha=0.2)
# plt.axis('scaled')


Pred_grid_xy = gs.Gridding.prediction_grid(xmin, xmax, ymin, ymax, resolution)
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.flip(np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))) # need to flip y otherwise the coordinate does not match
Pred_grid_xy = np.concatenate((x,y),axis=1)

for sgs_chain_index in range(9,num_sgs_chains):
    begin_time = time.time()
    
    bed = loaded_bed_sample[sgs_chain_index]
    
    file_postfix_list = ['_'+file_index+'_sgs_'+str(sgs_chain_index)+'_'+str(i) for i in range(1,21)]
    
    print('starting the chain',file_postfix_list[0])

    res_bed = bed - trend
    norm_res_bed = nst_trans.transform(res_bed.reshape(-1,1)).reshape(rows,cols)
    x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
    y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
    xy_grid = np.concatenate((x,y,norm_res_bed.flatten().reshape(-1,1)),axis=1)
    psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)
    
    #start crf in stages for easier storage
    for i in range(0,len(n_iter_list)):
        n_iter = n_iter_list[i]
        file_postfix = file_postfix_list[i]
        choice_param = choice_param_list[i]

        sigma_mc = sigma_mc_list[i]
        block_size = block_size_list[i]

        bed_cache, loss_mc_cache, loss_cache, step_cache, resampled_times, blocks_cache = geomc.sgs_chain(psimdf,'X', 'Y', 'Z', 
              nst_trans, trend, resolution, vario1_detrend,
              cond_data_mask, mc_region_mask,
              surf, velx, vely, dhdt, smb,
              n_iter, block_size, 
              mc_loss_type, sigma_mc, mcloss_in_high_vel,
              searching_radius, num_nearest_neighbors,
              rand_dropout, dropoutrate)

        res_bed = bed_cache[-1] - trend
        norm_res_bed = nst_trans.transform(res_bed.reshape(-1,1)).reshape(rows,cols)
        x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
        y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
        xy_grid = np.concatenate((x,y,norm_res_bed.flatten().reshape(-1,1)),axis=1)
        psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)

        if choice_param == 1: # save all data
            np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[:n_iter,:,:].reshape(n_iter, -1))
        else: # save a topo per choice_param topo
            choice = np.round(np.linspace(0, n_iter-choice_param, num=int(n_iter/choice_param))).astype(int)
            np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[choice,:,:].reshape(len(choice), -1))

        np.savetxt("loss_cache"+file_postfix+".txt",loss_cache[:n_iter])
        np.savetxt("loss_mc_cache"+file_postfix+".txt",loss_mc_cache[:n_iter])
        np.savetxt("step_cache"+file_postfix+".txt",step_cache[:n_iter])
        np.savetxt("resampled_times"+file_postfix+".txt",resampled_times)
        np.savetxt("blocks_cache"+file_postfix+".txt",blocks_cache)
        
    end_time = time.time()
    used_time = end_time - begin_time
    print('used ', used_time, ' seconds')





loaded_bed_temp = np.loadtxt("./59_sgs/bed_cache_59_sgs_8_16.txt")
loaded_bed_temp = loaded_bed_temp.reshape(np.round(loaded_bed_temp.size/(rows*cols)).astype(int), rows, cols)
bed = loaded_bed_temp[-1]
sgs_chain_index = 8

file_postfix_list = ['_'+file_index+'_sgs_'+str(sgs_chain_index)+'_'+str(i) for i in range(17,21)]

print('starting the chain',file_postfix_list[0])

res_bed = bed - trend
norm_res_bed = nst_trans.transform(res_bed.reshape(-1,1)).reshape(rows,cols)
x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
xy_grid = np.concatenate((x,y,norm_res_bed.flatten().reshape(-1,1)),axis=1)
psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)

#start crf in stages for easier storage
for i in range(0,len(n_iter_list)):
    n_iter = n_iter_list[i]
    file_postfix = file_postfix_list[i]
    choice_param = choice_param_list[i]

    sigma_mc = sigma_mc_list[i]
    block_size = block_size_list[i]

    bed_cache, loss_mc_cache, loss_cache, step_cache, resampled_times, blocks_cache = geomc.sgs_chain(psimdf,'X', 'Y', 'Z', 
          nst_trans, trend, resolution, vario1_detrend,
          cond_data_mask, mc_region_mask,
          surf, velx, vely, dhdt, smb,
          n_iter, block_size, 
          mc_loss_type, sigma_mc, mcloss_in_high_vel,
          searching_radius, num_nearest_neighbors,
          rand_dropout, dropoutrate)

    res_bed = bed_cache[-1] - trend
    norm_res_bed = nst_trans.transform(res_bed.reshape(-1,1)).reshape(rows,cols)
    x = np.reshape(Pred_grid_xy[:,0], (rows*cols, 1))
    y = np.reshape(Pred_grid_xy[:,1], (rows*cols, 1))
    xy_grid = np.concatenate((x,y,norm_res_bed.flatten().reshape(-1,1)),axis=1)
    psimdf = pd.DataFrame(data = xy_grid,columns=['X','Y','Z'],index=df.index)

    if choice_param == 1: # save all data
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[:n_iter,:,:].reshape(n_iter, -1))
    else: # save a topo per choice_param topo
        choice = np.round(np.linspace(0, n_iter-choice_param, num=int(n_iter/choice_param))).astype(int)
        np.savetxt("bed_cache"+file_postfix+".txt", bed_cache[choice,:,:].reshape(len(choice), -1))

    np.savetxt("loss_cache"+file_postfix+".txt",loss_cache[:n_iter])
    np.savetxt("loss_mc_cache"+file_postfix+".txt",loss_mc_cache[:n_iter])
    np.savetxt("step_cache"+file_postfix+".txt",step_cache[:n_iter])
    np.savetxt("resampled_times"+file_postfix+".txt",resampled_times)
    np.savetxt("blocks_cache"+file_postfix+".txt",blocks_cache)


used_time


'begin at Sept 23, 00:33'
'stopped at Sept 23, 10:57 because of range() set to wrong value, finished one sgs chain of 20 * 10000 iters'



'begin at Sept 15, 23:03'


'stopped at Sept 17, 20:50 because service of hipergator stopped, stoppped at sgs_6_13.'
'resume sept 17 22:50 from sgs_6_1'






