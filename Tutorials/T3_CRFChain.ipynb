{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba72c42-3157-49ea-9595-35149e93d8db",
   "metadata": {},
   "source": [
    "# Tutorial 3: Initializing a conditioning random field chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb172f80-8aa8-4eab-a278-b69ff3fdc978",
   "metadata": {},
   "source": [
    "### First, obtaining information we need as in T1 and T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330e51f3-185c-4d6d-ba82-2ed137cf92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load compiled bed elevation measurements\n",
    "df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706b660-7738-44dc-9937-a9db14e45534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a grid of x and y coordinates\n",
    "x_uniq = np.unique(df.X)\n",
    "y_uniq = np.unique(df.Y)\n",
    "\n",
    "xmin = np.min(x_uniq)\n",
    "xmax = np.max(x_uniq)\n",
    "ymin = np.min(y_uniq)\n",
    "ymax = np.max(y_uniq)\n",
    "\n",
    "cols = len(x_uniq)\n",
    "rows = len(y_uniq)\n",
    "\n",
    "resolution = 1000\n",
    "\n",
    "xx, yy = np.meshgrid(x_uniq, y_uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ba1c5-c2a3-4299-9009-063664ef54f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load other data\n",
    "velx, vely, velxerr, velyerr, fig = Topography.load_vel_measures('../../Data/antarctica_ice_velocity_450m_v2.nc', xx, yy)\n",
    "dhdt, fig = Topography.load_dhdt('../Data/ANT_G1920_GroundedIceHeight_v01.nc',xx,yy,interp_method='linear',begin_year = 2013,end_year=2015,month=7)\n",
    "smb, fig = Topography.load_smb_racmo('../Data/SMB_RACMO2.3p2_yearly_ANT27_1979_2016.nc', xx, yy, interp_method='spline',time=2014)\n",
    "bm_mask, bm_source, bm_bed, bm_surface, bm_errbed, fig = Topography.load_bedmachine('../../Data/BedMachineAntarctica-v3.nc', xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7294bad-439c-4634-8f05-05f4a9e21959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find variograms\n",
    "df_bed = df.copy()\n",
    "df_bed = df_bed[df_bed[\"bed\"].isnull() == False]\n",
    "data = df_bed['bed'].values.reshape(-1,1)\n",
    "coords = df_bed[['X','Y']].values\n",
    "roughness_region_mask = (df_bed['bedmachine_mask'].values)==2 # Read BedMachine user guide for the meaning of values == 2 https://nsidc.org/data/nsidc-0756/versions/3\n",
    "\n",
    "nst_trans, Nbed_radar, varios, fig = MCMC.fit_variogram(data, coords, roughness_region_mask, maxlag=70000, n_lags=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a4e01-3c75-420d-a5e4-0b361cdeed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate high velocity region\n",
    "ocean_mask = (bm_mask == 0) | (bm_mask == 3) # utilize the mask in BedMachine dataset to characterize ice regions\n",
    "grounded_ice_mask = (bm_mask == 2)\n",
    "distance_max = 3000\n",
    "velocity_threshold = 50\n",
    "highvel_mask = Topography.get_highvel_boundary(velx, vely, velocity_threshold, grounded_ice_mask, ocean_mask, distance_max, xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02661b7f-3b41-4c07-80d0-116af16303bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the initial bed\n",
    "sgs_bed = np.loadtxt('sgs_bed.txt')\n",
    "thickness = bm_surface - sgs_bed\n",
    "sgs_bed = np.where((thickness<=0)&(bm_mask==2), bm_surface-1, sgs_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dba47a-c995-4cbb-81a9-9252b6cd1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate conditioning data and a mask of conditioning data\n",
    "cond_bed = df['bed'].values.reshape(xx.shape)\n",
    "data_mask = ~np.isnan(cond_bed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f822608-c439-4c6e-8a5d-e8e3ddebb6ba",
   "metadata": {},
   "source": [
    "### Then initiating the chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5a9d8-6981-445b-bedf-92807128c53b",
   "metadata": {},
   "source": [
    "#### Initiate an object of the class chain_crf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28db42-4f04-470b-98a4-07b7875c83c2",
   "metadata": {},
   "source": [
    "Let's first initiate the chain. Here, we created an object of the class chain_crf. This initialization process requires several input that are essential for later calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b830c529-a055-461a-82be-fcde7a8196e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_1 = MCMC.chain_crf(xx, yy, bed, bm_surface, velx, vely, dhdt, smb, cond_bed, data_mask, grounded_ice_mask, resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c6c23-bc6b-4ebf-9bc1-c467640083cc",
   "metadata": {},
   "source": [
    "Now, the object 'crf_1' have all the properties you have assigned in the initialization process. Try typing *crf_1.xx* or *crf_1.cond_bed*, or any other argument to check them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1eb30-646d-4616-92ec-470a33f71637",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(xx, yy, crf_1.bm_surface)\n",
    "plt.axis('scaled')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce25df-8170-4966-b161-aed9e2faf10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(xx, yy, crf_1.data_mask)\n",
    "plt.axis('scaled')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d84217-0fba-4f6a-9a89-99a97e633c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(xx, yy, crf_1.velx)\n",
    "plt.axis('scaled')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1324cb1-3349-48a9-97a2-2a85271e06c7",
   "metadata": {},
   "source": [
    "The second function required, is *set_high_vel_region*. In this function, the first boolean argument decide whether the MCMC update will be inside the high velocity, the second argument specify the exact region of high velocity (where the high_vel_mask == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099b12c-4755-4dd0-8ed1-4bda7a6c9e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrf.set_high_vel_region(False,highvel_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf55b08-cdbe-4c69-922d-f2975fc9b6ec",
   "metadata": {},
   "source": [
    "We also want to specify how we want to define the loss function used in the chain.\n",
    "\n",
    "*map_func* determine the distribution of mass conservation residuals, whereas the *diff_func* determine the distribution of the difference between radar measurements and simulated topography. If the residuals has a Gaussian distribution, the corresponding function will be 'sumsquare'. If you do not want to include either of these loss, simple put *map_func = None* or *diff_func = None*. \n",
    "\n",
    "*sigma_mc* and *sigma_data* determine the standard deviation of the distribution of mass conservation residual or differences to radar data. *massConvInRegion* and *dataDiffInRegion* specify whether the two losses should be calculated for only inside the high velocity region or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc53376-caa0-4e93-8513-a80955f1e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrf.set_loss_type(map_func='sumsquare', diff_func='sumsquare', sigma_mc=3, sigma_data=80, massConvInRegion=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7739595-6330-4c60-9d9a-0dc28c96ac24",
   "metadata": {},
   "source": [
    "#### Initiate an object of the class RandField"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c038db8a-c61d-41be-bb78-ebfcabd39375",
   "metadata": {},
   "source": [
    "Next step is to set up the parameters of the random field perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d9fb0-5cd0-4fc8-8efc-38d8cc086ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_max_x = 50e3 #in terms of meters in lateral dimension, regardless of resolution of the map\n",
    "range_max_y = 50e3\n",
    "range_min_x = 10e3\n",
    "range_min_y = 10e3\n",
    "scale_min = 100 #in terms of meters in vertical dimension, how much you want to multiply the perturbation by\n",
    "scale_max = 400\n",
    "nugget_max = 0\n",
    "random_field_model = 'Exponential' # currently only supporting 'Gaussian' or 'Exponential'\n",
    "isotropic = True\n",
    "\n",
    "rf1 = MCMC.RandField(range_max_x, range_max_y, range_min_x, range_min_y, scale_min, scale_max, nugget_max, random_field_model, isotropic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b255b47f-7430-4a5a-a788-5a3f599bc874",
   "metadata": {},
   "source": [
    "Then we can set up the size of the blocks used in the update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682d797-0c7f-4c27-93a7-46610eff3e88",
   "metadata": {},
   "source": [
    "*set_block_sizes* function create a list of possible block sizes, which will be accessible via rf1.pairs after the function is called.\n",
    "\n",
    "*set_block_sizes* function also has an optional argument *steps*, it specify how many 'steps' between the min_block and max_block will be divided into. For example, for min_block_x = 20 and max_block_x = 50, steps = 4 will divide the range into [20, 30, 40, 50]. For min_block_y = 10 and max_block_y = 55, it will divide the range into [10, 25, 40, 55]. Then each size on the list for x will pair up with all size on the list for y, creating a list of following\n",
    "\n",
    "rf1.pairs = [[20,10],[20,25],[20,40],[20,55],[30,10],[30,25],[30,40],[30,55],[40,10],[40,25],[40,40],[40,55],[50,10],[50,25],[50,40],[50,55]]\n",
    "\n",
    "When randomly deciding the size of the block, one of the size on the list will be chosen and will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63d8f2-3536-4a9f-ad4b-076575c6e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_block_x = 20\n",
    "max_block_x = 50\n",
    "min_block_y = 20\n",
    "max_block_y = 50\n",
    "rf1.set_block_sizes(min_block_x, max_block_x, min_block_y, max_block_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068f30f-6781-4d5d-ae0f-afbe15dc16f0",
   "metadata": {},
   "source": [
    "Finally, if you wish to use conditional block update, then the RandField object requires specifying the logistic function used to calculate the conditioning weight of the random field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fba7f5-548f-40f9-9ef9-49121dd085e3",
   "metadata": {},
   "source": [
    "The logistic function is used to calculate the weight for conditioning to the edge of the block and the weight for conditioning to radar measurements. When updating the field, the weight will be 1 at conditioning data and block edges, and it logistically decays to 0 at location *max_dist* away from any conditioning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ddfef-70cf-4e61-9d94-89c27df5cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logis_func_L = 2\n",
    "logis_func_x0 = 0\n",
    "logis_func_k = 6\n",
    "logis_func_offset = 1\n",
    "max_dist = varios[2][0] # set to the distance between two points on the map where the correlation vanish / is minimal\n",
    "\n",
    "rf1.set_block_param(logis_func_L, logis_func_x0, logis_func_k, logis_func_offset, max_dist, resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c880b2d8-e35c-4553-8745-e084ea8bdfce",
   "metadata": {},
   "source": [
    "#### Run the Markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f80c2-ee73-41df-8dcd-b01186865e55",
   "metadata": {},
   "source": [
    "At last, these information need to be known to the crf chain. The function *set_crf_data_weight* calculate the weight for conditioning to the radar measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908befa4-4ff7-4524-bc1c-eaf231b1a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrf.set_crf_data_weight(rf1)\n",
    "ccrf.set_update_type('RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ce3cc-5617-43e1-b2dc-4d49984340fe",
   "metadata": {},
   "source": [
    "And then we can start the chain by specifying how many iterations it should go through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43e67d-a0d7-4be8-bca1-f0cddc68c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "randomGenerator = np.random.default_rng(seed)\n",
    "\n",
    "bed_cache, loss_mc_cache, loss_data_cache, loss_cache, step_cache, resampled_times, blocks_cache = ccrf.run(n_iter=5000, RF=rf1, rng=randomGenerator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostatskernel",
   "language": "python",
   "name": "geostatskernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
